{"cells":[{"cell_type":"markdown","metadata":{},"source":["# SIIM MMDetection train demo notebook"]},{"cell_type":"markdown","metadata":{},"source":["This notebook uses [MMDetection](https://github.com/open-mmlab/mmdetection) framework to identify opacity bounding boxes in the SIIM competition."]},{"cell_type":"markdown","metadata":{},"source":["[This dataset](https://www.kaggle.com/xhlulu/siim-covid19-resized-to-512px-png) is used for the train process, so please upvote it."]},{"cell_type":"markdown","metadata":{},"source":["## Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:26:21.079894Z","iopub.status.busy":"2021-05-24T08:26:21.079432Z","iopub.status.idle":"2021-05-24T08:28:28.562188Z","shell.execute_reply":"2021-05-24T08:28:28.561283Z","shell.execute_reply.started":"2021-05-24T08:26:21.079815Z"},"trusted":true},"outputs":[],"source":["# !pip install ../input/mmdet2100/mmdetection-2.10.0/addict-2.4.0-py3-none-any.whl\n","# !pip install ../input/mmdet2100/mmdetection-2.10.0/yapf-0.31.0-py2.py3-none-any.whl\n","# !pip install ../input/pycocotools202/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\n","# !pip install ../input/mmcvfull134/mmcv_full-1.3.4-cp37-cp37m-manylinux1_x86_64.whl\n","# !pip install ../input/mmdetection2120/mmdetection-2.12.0 -f ./ --no-index\n","# !pip install ../input/ensemble-boxes-104/ensemble_boxes-1.0.4/ -f ./ --no-index"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:28.565717Z","iopub.status.busy":"2021-05-24T08:28:28.565463Z","iopub.status.idle":"2021-05-24T08:28:47.685651Z","shell.execute_reply":"2021-05-24T08:28:47.684131Z","shell.execute_reply.started":"2021-05-24T08:28:28.565691Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.12.0\n"]}],"source":["import os\n","import shutil\n","import yaml\n","import time\n","import json\n","import cv2\n","import random\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import GroupKFold, StratifiedKFold\n","from tqdm.notebook import tqdm\n","import seaborn as sns\n","import torch\n","from IPython.display import Image, clear_output\n","from collections import Counter\n","from ensemble_boxes import *\n","import copy\n","import os.path as osp\n","import mmcv\n","import mmdet\n","import numpy as np\n","import albumentations as A\n","from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.custom import CustomDataset\n","from mmcv import Config\n","from mmdet.apis import set_random_seed\n","from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n","from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","print(mmdet.__version__)\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","path_dicom = Path('/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid19-detection')\n","labels_dcm_image = 'train_image_level.csv'\n","labels_dcm_study = 'train_study_level.csv'"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:47.688095Z","iopub.status.busy":"2021-05-24T08:28:47.687738Z","iopub.status.idle":"2021-05-24T08:28:47.698874Z","shell.execute_reply":"2021-05-24T08:28:47.698135Z","shell.execute_reply.started":"2021-05-24T08:28:47.688059Z"},"trusted":true},"outputs":[],"source":["VER = 'v1'\n","DEBUG = False\n","PARAMS = {\n","    'version': VER,\n","    'folds': 4,\n","    'val_fold': 0,\n","    'img_size': 512,\n","    'batch_size': 10,\n","    'epochs': 8,\n","    'seed': 2021,\n","    'iou_th': .6,\n","    'th': .5,\n","    ### r50\n","    'config': 'vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco.py',\n","    'checkpoint': 'vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth',\n","    ### r101\n","    #'config': 'vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco.py',\n","    #'checkpoint': 'vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth',\n","    'comments': ''\n","}\n","DATA_PATH = path_dicom\n","IMGS_PATH = path_dicom / 'input/siim-covid19-resized-to-512px-png'\n","CHKP_PATH = path_dicom / 'input/mmdet-vfnet-pretrained'\n","MDLS_PATH = path_dicom / f'working/models_mmdet_{VER}'\n","if not os.path.exists(MDLS_PATH):\n","    os.mkdir(MDLS_PATH)\n","with open(f'{MDLS_PATH}/params.json', 'w') as file:\n","    json.dump(PARAMS, file)\n","    \n","def seed_all(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","seed_all(PARAMS['seed'])\n","start_time = time.time()"]},{"cell_type":"markdown","metadata":{},"source":["## Data preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:47.702065Z","iopub.status.busy":"2021-05-24T08:28:47.701821Z","iopub.status.idle":"2021-05-24T08:28:47.858808Z","shell.execute_reply":"2021-05-24T08:28:47.858044Z","shell.execute_reply.started":"2021-05-24T08:28:47.702043Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f'{IMGS_PATH}/meta.csv')\n","train_df = train_df[train_df.split == 'train']\n","del train_df['split']\n","if DEBUG:\n","    train_df = train_df.loc[:100]\n","df_train_img = pd.read_csv(f'{DATA_PATH}/train_image_level.csv')\n","df_train_sty = pd.read_csv(f'{DATA_PATH}/train_study_level.csv')\n","\n","train_df['id'] = train_df['image_id'].apply(lambda x: ''.join([x.split('/')[-1], '_image']))\n","df_train_sty['StudyInstanceUID'] = df_train_sty['id'].apply(lambda x: x.replace('_study', ''))\n","del df_train_sty['id']\n","df_train_img = df_train_img.merge(df_train_sty, on='StudyInstanceUID')\n","train_df = df_train_img.merge(train_df, on='id')\n","train_df['img'] = train_df['image_id'] + '.png'\n","print(train_df.shape)\n","display(train_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:47.861507Z","iopub.status.busy":"2021-05-24T08:28:47.861258Z","iopub.status.idle":"2021-05-24T08:28:48.00883Z","shell.execute_reply":"2021-05-24T08:28:48.008032Z","shell.execute_reply.started":"2021-05-24T08:28:47.861483Z"},"trusted":true},"outputs":[],"source":["def bar_plot(train_df, variable):\n","    var = train_df[variable]\n","    varValue = var.value_counts()\n","    plt.figure(figsize = (12, 3))\n","    plt.bar(varValue.index, varValue)\n","    plt.xticks(varValue.index, varValue.index.values)\n","    plt.ylabel(\"Frequency\")\n","    plt.title(variable)\n","    plt.show()\n","    print(\"{}: \\n{}\".format(variable, varValue))\n","\n","train_df['target'] = 'Negative for Pneumonia'\n","train_df.loc[train_df['Typical Appearance']==1, 'target'] = 'Typical Appearance'\n","train_df.loc[train_df['Indeterminate Appearance']==1, 'target'] = 'Indeterminate Appearance'\n","train_df.loc[train_df['Atypical Appearance']==1, 'target'] = 'Atypical Appearance'\n","bar_plot(train_df, 'target') "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.010373Z","iopub.status.busy":"2021-05-24T08:28:48.010038Z","iopub.status.idle":"2021-05-24T08:28:48.028025Z","shell.execute_reply":"2021-05-24T08:28:48.027256Z","shell.execute_reply.started":"2021-05-24T08:28:48.010337Z"},"trusted":true},"outputs":[],"source":["train_df = train_df[~train_df.boxes.isnull()] \n","train_df.reset_index(inplace=True)\n","classes = [\n","    'Typical Appearance', \n","    'Indeterminate Appearance', \n","    'Atypical Appearance'\n","]\n","print('classes:\\n', classes,\n","      '\\nclasses labels:\\n', np.unique(train_df[classes].values, axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.029592Z","iopub.status.busy":"2021-05-24T08:28:48.029228Z","iopub.status.idle":"2021-05-24T08:28:48.045388Z","shell.execute_reply":"2021-05-24T08:28:48.044622Z","shell.execute_reply.started":"2021-05-24T08:28:48.029556Z"},"trusted":true},"outputs":[],"source":["label2color = {\n","    '[1, 0, 0]': [255, 0, 0], # Typical Appearance\n","    '[0, 1, 0]': [0, 255, 0], # Indeterminate Appearance\n","    '[0, 0, 1]': [0, 0, 255], # Atypical Appearance\n","}\n","label2classes = {\n","    '[1, 0, 0]': classes[0],\n","    '[0, 1, 0]': classes[1],\n","    '[0, 0, 1]': classes[2]\n","}\n","\n","def plot_img(img, size=(18, 18), title='', cmap='gray'):\n","    plt.figure(figsize=size)\n","    plt.imshow(img, cmap=cmap)\n","    plt.suptitle(title)\n","    plt.show()\n","\n","def plot_imgs(imgs, cols=2, size=10, is_rgb=True, title='', cmap='gray', img_size=None):\n","    rows = len(imgs) // cols + 1\n","    fig = plt.figure(figsize=(cols * size, rows * size))\n","    for i, img in enumerate(imgs):\n","        if img_size is not None:\n","            img = cv2.resize(img, img_size)\n","        fig.add_subplot(rows, cols, i + 1)\n","        plt.axis('off')\n","        plt.imshow(img, cmap=cmap)\n","    plt.suptitle(title)\n","    plt.axis('off')\n","    \n","def draw_bbox(img, box, label, color, thickness=3):   \n","    alpha = .1\n","    alpha_box = .4\n","    overlay_bbox = img.copy()\n","    overlay_text = img.copy()\n","    output = img.copy()\n","    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, .6, 1)[0]\n","    cv2.rectangle(overlay_bbox, \n","                  (box[0], box[1]), \n","                  (box[2], box[3]), \n","                  color, -1)\n","    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n","    cv2.rectangle(overlay_text, \n","                  (box[0], box[1] - 7 - text_height), \n","                  (box[0] + text_width + 2, box[1]),\n","                  (0, 0, 0), -1)\n","    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n","    cv2.rectangle(output, \n","                  (box[0], box[1]), \n","                  (box[2], box[3]),\n","                  color, thickness)\n","    cv2.putText(output, \n","                label.upper(), \n","                (box[0], box[1]-5),\n","                cv2.FONT_HERSHEY_SIMPLEX, \n","                .6, (255, 255, 255), 1, \n","                cv2.LINE_AA)\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.048648Z","iopub.status.busy":"2021-05-24T08:28:48.04805Z","iopub.status.idle":"2021-05-24T08:28:48.691201Z","shell.execute_reply":"2021-05-24T08:28:48.690429Z","shell.execute_reply.started":"2021-05-24T08:28:48.048596Z"},"trusted":true},"outputs":[],"source":["imgs = []\n","sample = train_df.sample(n=4)['img'].values\n","for img_name in sample:\n","    ratio_x = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim1'].values[0]\n","    ratio_y = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim0'].values[0]\n","    boxes = train_df.loc[train_df['img'] == img_name, 'boxes'].values[0]\n","    boxes = json.loads(boxes.replace('\\'', '\\\"'))\n","    boxes = [[int(box['x'] * ratio_x), \n","              int(box['y'] * ratio_y), \n","              int((box['x'] + box['width']) * ratio_x), \n","              int((box['y'] + box['height']) * ratio_y)]\n","             for box in boxes]\n","    img_labels = train_df.loc[train_df['img'] == img_name, classes].values[0]\n","    img_labels = [str(img_labels.tolist())] * len(boxes)\n","    img = cv2.imread(f'{IMGS_PATH}/train/{img_name}')\n","    for label_id, box in zip(img_labels, boxes):\n","        color = label2color[label_id]\n","        img = draw_bbox(\n","            img, \n","            list(np.int_(box)), \n","            label2classes[label_id], \n","            label2color[label_id]\n","        )\n","    imgs.append(img)\n","plot_imgs(imgs, size=8, cols=4, cmap=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.69278Z","iopub.status.busy":"2021-05-24T08:28:48.692492Z","iopub.status.idle":"2021-05-24T08:28:48.711777Z","shell.execute_reply":"2021-05-24T08:28:48.71101Z","shell.execute_reply.started":"2021-05-24T08:28:48.692751Z"},"trusted":true},"outputs":[],"source":["skf  = StratifiedKFold(n_splits=PARAMS['folds'])\n","train_df['fold'] = -1\n","for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y=train_df.target)):\n","    train_df.loc[val_idx, 'fold'] = fold"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.713457Z","iopub.status.busy":"2021-05-24T08:28:48.713028Z","iopub.status.idle":"2021-05-24T08:28:48.726065Z","shell.execute_reply":"2021-05-24T08:28:48.725266Z","shell.execute_reply.started":"2021-05-24T08:28:48.713421Z"},"trusted":true},"outputs":[],"source":["split = PARAMS['val_fold']\n","with open(f'{MDLS_PATH}/train.txt', 'w') as file:\n","    tr_ids = list(train_df[train_df['fold'] != split].img.unique())\n","    print('train:', len(tr_ids))\n","    file.write('\\n'.join(tr_ids))\n","with open(f'{MDLS_PATH}/val.txt', 'w') as file:\n","    val_ids = list(train_df[train_df['fold'] == split].img.unique())\n","    print('val:', len(val_ids))\n","    file.write('\\n'.join(val_ids))"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.727799Z","iopub.status.busy":"2021-05-24T08:28:48.727452Z","iopub.status.idle":"2021-05-24T08:28:48.740617Z","shell.execute_reply":"2021-05-24T08:28:48.739857Z","shell.execute_reply.started":"2021-05-24T08:28:48.727763Z"},"trusted":true},"outputs":[],"source":["@DATASETS.register_module()\n","class SIIMDataset(CustomDataset):\n","    CLASSES = ('opacity', )\n","    ANN_DF = train_df.copy()\n","    def load_annotations(self, ann_file):\n","        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n","        image_list = mmcv.list_from_file(self.ann_file)\n","        data_infos = []\n","        for img_id in image_list:\n","            img_anns = self.ANN_DF[self.ANN_DF.img == img_id]\n","            filename = f'{self.img_prefix}/{img_anns[\"img\"].values[0]}'\n","            data_info = dict(\n","                filename=filename, \n","                width=PARAMS['img_size'], \n","                height=PARAMS['img_size']\n","            )\n","            ratio_x = PARAMS['img_size'] / img_anns['dim1'].values[0]\n","            ratio_y = PARAMS['img_size'] / img_anns['dim0'].values[0]\n","            boxes = img_anns['boxes'].values[0]\n","            boxes = json.loads(boxes.replace('\\'', '\\\"'))\n","            gt_bboxes = [\n","                [int(box['x'] * ratio_x), \n","                 int(box['y'] * ratio_y), \n","                 int((box['x'] + box['width']) * ratio_x), \n","                 int((box['y'] + box['height']) * ratio_y)]\n","                for box in boxes]\n","            img_labels = img_anns[classes].values[0]\n","            gt_labels = [0] * len(boxes)\n","            data_anno = dict(\n","                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n","                labels=np.array(gt_labels),\n","            )\n","            data_info.update(ann=data_anno)\n","            data_infos.append(data_info)\n","        return data_infos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.743729Z","iopub.status.busy":"2021-05-24T08:28:48.743492Z","iopub.status.idle":"2021-05-24T08:28:48.752599Z","shell.execute_reply":"2021-05-24T08:28:48.751745Z","shell.execute_reply.started":"2021-05-24T08:28:48.743706Z"},"trusted":true},"outputs":[],"source":["train_transforms = A.Compose([\n","    A.OneOf([\n","        A.RandomBrightness(limit=.2, p=1), \n","        A.RandomContrast(limit=.2, p=1), \n","        A.RandomGamma(p=1)\n","    ], p=.5),\n","    A.OneOf([\n","        A.Blur(blur_limit=3, p=1),\n","        A.MedianBlur(blur_limit=3, p=1)\n","    ], p=.25),\n","    A.OneOf([\n","        A.GaussNoise(0.002, p=.5),\n","        A.IAAAffine(p=.5),\n","    ], p=.25),\n","    A.VerticalFlip(p=.5),\n","    A.HorizontalFlip(p=.5),\n","    A.Transpose(p=.25),\n","    A.RandomRotate90(p=.25),\n","    A.Cutout(num_holes=10, max_h_size=20, max_w_size=20, p=.25),\n","    A.ShiftScaleRotate(p=.5)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:48.754238Z","iopub.status.busy":"2021-05-24T08:28:48.753903Z","iopub.status.idle":"2021-05-24T08:28:52.198005Z","shell.execute_reply":"2021-05-24T08:28:52.197059Z","shell.execute_reply.started":"2021-05-24T08:28:48.754203Z"},"trusted":true},"outputs":[],"source":["cfg = Config.fromfile(f'../input/mmdetection2120/mmdetection-2.12.0/configs/vfnet/{PARAMS[\"config\"]}')\n","cfg.load_from = f'{CHKP_PATH}/{PARAMS[\"checkpoint\"]}'\n","cfg.model.bbox_head.num_classes = 1\n","cfg.dump(f'{MDLS_PATH}/init_config.py')\n","cfg.train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(\n","        type='Resize',\n","        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n","                   (1333, 768), (1333, 800)],\n","        multiscale_mode='value',\n","        keep_ratio=True),\n","    ########################################\n","    # Note that this key is part of bbox_params. \n","    # Their difference is format='pascal_voc' means [x1, y1, x2, y2] style box encoding, \n","    # while format='coco' means [x, y, w, h].\n","    dict(\n","        type='Albu',\n","        transforms=train_transforms,\n","        bbox_params=dict(\n","            type='BboxParams',\n","            format='pascal_voc',\n","            label_fields=['gt_labels'],\n","            min_visibility=0.0,\n","            filter_lost_elements=True),\n","        keymap={\n","            'img': 'image',\n","            'gt_bboxes': 'bboxes'},\n","        update_pad_shape=False,\n","        skip_img_without_anno=True),\n","    #########################################\n","    dict(\n","        type='Normalize',\n","        mean=[103.53, 116.28, 123.675],\n","        std=[1.0, 1.0, 1.0],\n","        to_rgb=False),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","cfg.dataset_type = 'SIIMDataset'\n","cfg.data_root = f'{IMGS_PATH}/train'\n","cfg.data.test.type = 'SIIMDataset'\n","cfg.data.test.data_root = IMGS_PATH\n","cfg.data.test.ann_file = f'{MDLS_PATH}/train.txt'\n","cfg.data.test.img_prefix = ''\n","cfg.data.train.type = 'SIIMDataset'\n","cfg.data.train.data_root = f'{IMGS_PATH}/train'\n","cfg.data.train.ann_file = f'{MDLS_PATH}/train.txt'\n","cfg.data.train.img_prefix = ''\n","cfg.data.val.type = 'SIIMDataset'\n","cfg.data.val.data_root = f'{IMGS_PATH}/train'\n","cfg.data.val.ann_file = f'{MDLS_PATH}/val.txt'\n","cfg.data.val.img_prefix = ''\n","cfg.work_dir = MDLS_PATH\n","cfg.optimizer.lr = .02 / (8 * 16 / PARAMS['batch_size'])\n","cfg.log_config.interval = 128\n","cfg.runner.max_epochs = PARAMS['epochs']\n","cfg.checkpoint_config.interval = 1\n","cfg.evaluation = dict(\n","    interval=1, \n","    start=2,\n","    metric='mAP', \n","    save_best='mAP')\n","cfg.seed = PARAMS['seed']\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.data.samples_per_gpu = PARAMS['batch_size']\n","cfg.data.workers_per_gpu = 2\n","cfg.workflow = [('train', 1)]\n","cfg.dump(f'{MDLS_PATH}/train_config.py')\n","print(f'Config:\\n{cfg.pretty_text}')\n","\n","elapsed_time = time.time() - start_time\n","print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T08:28:52.199607Z","iopub.status.busy":"2021-05-24T08:28:52.199253Z"},"trusted":true},"outputs":[],"source":["datasets = [build_dataset(cfg.data.train)]\n","if len(cfg.workflow) == 2:\n","    datasets.append(build_dataset(cfg.data.val))\n","model = build_detector(\n","    cfg.model, \n","    train_cfg=cfg.get('train_cfg'), \n","    test_cfg=cfg.get('test_cfg')\n",")\n","model.CLASSES = datasets[0].CLASSES\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","train_detector(model, datasets, cfg, distributed=False, validate=True)\n","\n","elapsed_time = time.time() - start_time\n","print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"]},{"cell_type":"markdown","metadata":{},"source":["## Inference demo"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint = f'{MDLS_PATH}/epoch_8.pth'\n","cfg = f'{MDLS_PATH}/init_config.py'\n","model_test = init_detector(cfg, checkpoint, device='cuda:0')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["imgs = []\n","split = PARAMS['val_fold']\n","sample = train_df[train_df['fold'] != split].sample(n=4)['img'].values\n","for img_name in sample:\n","    ratio_x = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim1'].values[0]\n","    ratio_y = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim0'].values[0]\n","    boxes = train_df.loc[train_df['img'] == img_name, 'boxes'].values[0]\n","    boxes = json.loads(boxes.replace('\\'', '\\\"'))\n","    boxes = [[int(box['x'] * ratio_x), \n","              int(box['y'] * ratio_y), \n","              int((box['x'] + box['width']) * ratio_x), \n","              int((box['y'] + box['height']) * ratio_y)]\n","             for box in boxes]\n","    img_labels = train_df.loc[train_df['img'] == img_name, classes].values[0]\n","    img_labels = [str(img_labels.tolist())] * len(boxes)\n","    img = cv2.imread(f'{IMGS_PATH}/train/{img_name}')\n","    for label_id, box in zip(img_labels, boxes):\n","        color = label2color[label_id]\n","        img = draw_bbox(\n","            img, \n","            list(np.int_(box)), \n","            label2classes[label_id], \n","            label2color[label_id]\n","        )\n","    result = inference_detector(model_test, img)\n","    boxes_list = [list(x[:, :4] / PARAMS['img_size']) for x in result if x.shape[0] != 0]\n","    boxes_list =  [item for sublist in boxes_list for item in sublist]\n","    scores_list = [x[:, 4].tolist() for x in result if x.shape[0] != 0]\n","    scores_list =  [item for sublist in scores_list for item in sublist]\n","    labels_list = [[i] * x.shape[0] for i, x in enumerate(result) if x.shape[0] != 0]\n","    labels_list =  [item for sublist in labels_list for item in sublist]\n","    boxes, scores, box_labels = nms(\n","        boxes=[boxes_list], \n","        scores=[scores_list], \n","        labels=[labels_list], \n","        weights=None,\n","        iou_thr=PARAMS['iou_th']\n","    )\n","    boxes *= PARAMS['img_size']\n","    for label_id, box, score in zip(box_labels, boxes, scores):\n","        if score >= PARAMS['th']:\n","            color = [255, 255, 255]\n","            img = draw_bbox(\n","                img, \n","                list(np.int_(box)), \n","                'predict', \n","                color\n","            )\n","    imgs.append(img)\n","plot_imgs(imgs, size=8, cols=4, cmap=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["elapsed_time = time.time() - start_time\n","print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.5 64-bit ('icevision-dcm': venv)","name":"icevision-dcm"},"language_info":{"name":"python","version":""},"orig_nbformat":3},"nbformat":4,"nbformat_minor":4}