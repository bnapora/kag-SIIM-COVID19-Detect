{"cells":[{"cell_type":"markdown","metadata":{},"source":["This is a starter kernel to train a YOLOv5 model on [SIIM-FISABIO-RSNA COVID-19 Detection](https://www.kaggle.com/c/siim-covid19-detection/overview) dataset. Given an input image the task is to find the region of opacity in the chest  using bounding box coordinates. Check out [Visualize Bounding Boxes Interactively](https://www.kaggle.com/ayuraj/visualize-bounding-boxes-interactively) for interactive bounding box EDA. \n","\n","## üñºÔ∏è What is YOLOv5?\n","\n","YOLO an acronym for 'You only look once', is an object detection algorithm that divides images into a grid system. Each cell in the grid is responsible for detecting objects within itself.\n","\n","[Ultralytics' YOLOv5](https://ultralytics.com/yolov5) (\"You Only Look Once\") model family enables real-time object detection with convolutional neural networks. \n","\n","## ü¶Ñ What is Weights and Biases?\n","\n","Weights & Biases (W&B) is a set of machine learning tools that helps you build better models faster. Check out [Experiment Tracking with Weights and Biases](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases) to learn more.  \n","Weights & Biases is directly integrated into YOLOv5, providing experiment metric tracking, model and dataset versioning, rich model prediction visualization, and more.\n","\n","\n","It's a work in progress:\n","\n","‚úîÔ∏è Required folder structure. <br>\n","‚úîÔ∏è Bounding box format required for YOLOv5. <br>\n","‚úîÔ∏è **Train** a small YOLOv5 model. <br>\n","‚úîÔ∏è Experiment tracking with W&B. <br>\n","‚úîÔ∏è Proper documentation <br>\n","‚úîÔ∏è Inference <br>\n","\n","‚ùå Model prediction visualization. \n","\n","## Results \n","\n","### [Check out W&B Run Page $\\rightarrow$](https://wandb.ai/ayush-thakur/kaggle-siim-covid/runs/1bk93e3j)\n","\n","![img](https://i.imgur.com/quOYtNN.gif)"]},{"cell_type":"markdown","metadata":{},"source":["# ‚òÄÔ∏è Imports and Setup\n","\n","According to the official [Train Custom Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data) guide, YOLOv5 requires a certain directory structure. \n","\n","```\n","/parent_folder\n","    /dataset\n","         /images\n","         /labels\n","    /yolov5\n","```\n","\n","* We thus will create a `/tmp` directory. <br>\n","* Download YOLOv5 repository and pip install the required dependencies. <br>\n","* Install the latest version of W&B and login with your wandb account. You can create your free W&B account [here](https://wandb.ai/site)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:23:59.355472Z","iopub.status.busy":"2021-06-01T18:23:59.355119Z","iopub.status.idle":"2021-06-01T18:23:59.99861Z","shell.execute_reply":"2021-06-01T18:23:59.997685Z","shell.execute_reply.started":"2021-06-01T18:23:59.355393Z"},"trusted":true},"outputs":[],"source":["# %cd ../\n","# !mkdir tmp\n","# %cd tmp"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:24:02.961015Z","iopub.status.busy":"2021-06-01T18:24:02.960702Z","iopub.status.idle":"2021-06-01T18:24:24.207951Z","shell.execute_reply":"2021-06-01T18:24:24.206845Z","shell.execute_reply.started":"2021-06-01T18:24:02.960984Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup complete. Using torch 1.8.1+cu102 (NVIDIA GeForce RTX 2080 Super with Max-Q Design)\n"]}],"source":["# # Download YOLOv5\n","# !git clone https://github.com/ultralytics/yolov5  # clone repo\n","# %cd yolov5\n","# # Install dependencies\n","# %pip install -qr requirements.txt  # install dependencies\n","\n","# %cd ../\n","import torch\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:24:24.20989Z","iopub.status.busy":"2021-06-01T18:24:24.209559Z","iopub.status.idle":"2021-06-01T18:24:56.097462Z","shell.execute_reply":"2021-06-01T18:24:56.096631Z","shell.execute_reply.started":"2021-06-01T18:24:24.209848Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":"True"},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Install W&B \n","# !pip install -q --upgrade wandb\n","# Login \n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-06-01T18:27:29.197843Z","iopub.status.busy":"2021-06-01T18:27:29.197448Z","iopub.status.idle":"2021-06-01T18:27:30.205488Z","shell.execute_reply":"2021-06-01T18:27:30.204651Z","shell.execute_reply.started":"2021-06-01T18:27:29.197803Z"},"trusted":true},"outputs":[],"source":["# Necessary/extra dependencies. \n","import os\n","import gc\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from shutil import copyfile\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"markdown","metadata":{},"source":["# ü¶Ü Hyperparameters"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:27:37.997453Z","iopub.status.busy":"2021-06-01T18:27:37.996997Z","iopub.status.idle":"2021-06-01T18:27:38.004813Z","shell.execute_reply":"2021-06-01T18:27:38.004014Z","shell.execute_reply.started":"2021-06-01T18:27:37.997415Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","path = Path('./')\n","\n","# Laptop Workstation\n","path_dicom = Path('/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid19-detection')\n","\n","# AZ Server\n","# path_dicom = Path('/workspace/WSI/SIIM-Covid19-Detection')\n","\n","TRAIN_PATH = str(path_dicom) + '/train/'\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10"]},{"cell_type":"markdown","metadata":{},"source":["# üî® Prepare Dataset\n","\n","This is the most important section when it comes to training an object detector with YOLOv5. The directory structure, bounding box format, etc must be in the correct order. This section builds every piece needed to train a YOLOv5 model.\n","\n","I am using [xhlulu's](https://www.kaggle.com/xhlulu) resized dataset. The uploaded 256x256 Kaggle dataset is [here](https://www.kaggle.com/xhlulu/siim-covid19-resized-to-256px-jpg). Find other image resolutions [here](https://www.kaggle.com/c/siim-covid19-detection/discussion/239918).\n","\n","* Create train-validation split. <br>\n","* Create required `/dataset` folder structure and more the images to that folder. <br>\n","* Create `data.yaml` file needed to train the model. <br>\n","* Create bounding box coordinates in the required YOLO format. "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:27:49.71882Z","iopub.status.busy":"2021-06-01T18:27:49.718487Z","iopub.status.idle":"2021-06-01T18:27:50.040414Z","shell.execute_reply":"2021-06-01T18:27:50.039409Z","shell.execute_reply.started":"2021-06-01T18:27:49.71879Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/workspace/kag-SIIM-COVID19-Detect\n"]},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>boxes</th>\n      <th>label</th>\n      <th>StudyInstanceUID</th>\n      <th>path</th>\n      <th>image_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000a312787f2</td>\n      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n      <td>5776db0cec75</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>opacity</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c3a3f293f</td>\n      <td>NaN</td>\n      <td>none 1 0 0 1 1</td>\n      <td>ff0879eb20ed</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0012ff7358bc</td>\n      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n      <td>9d514ce429a7</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>opacity</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001398f4ff4f</td>\n      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n      <td>28dddc8559b2</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>opacity</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001bd15d1891</td>\n      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n      <td>dfd9fdd85a3e</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>opacity</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             id                                              boxes  \\\n0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n1  000c3a3f293f                                                NaN   \n2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n\n                                               label StudyInstanceUID  \\\n0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n1                                     none 1 0 0 1 1     ff0879eb20ed   \n2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n\n                                                path image_level  \n0  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...     opacity  \n1  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...        none  \n2  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...     opacity  \n3  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...     opacity  \n4  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...     opacity  "},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Everything is done from /kaggle directory.\n","%cd ../\n","\n","# Load image level csv file\n","df = pd.read_csv(path_dicom / 'train_image_level.csv')\n","\n","# Modify values in the id column\n","df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n","# Add absolute path\n","df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n","# Get image level labels\n","df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n","\n","df.head(5)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:27:56.041812Z","iopub.status.busy":"2021-06-01T18:27:56.041493Z","iopub.status.idle":"2021-06-01T18:27:56.078201Z","shell.execute_reply":"2021-06-01T18:27:56.077241Z","shell.execute_reply.started":"2021-06-01T18:27:56.041781Z"},"trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dim0</th>\n      <th>dim1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1263</th>\n      <td>d8ba599611e5</td>\n      <td>2336</td>\n      <td>2836</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>29b23a11d1e4</td>\n      <td>3488</td>\n      <td>4256</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                id  dim0  dim1\n1263  d8ba599611e5  2336  2836\n1264  29b23a11d1e4  3488  4256"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Load meta.csv file\n","# Original dimensions are required to scale the bounding box coordinates appropriately.\n","\n","meta_df = pd.read_csv(path_dicom / 'DS-xhlulu_256/meta.csv')\n","train_meta_df = meta_df.loc[meta_df.split == 'train']\n","train_meta_df = train_meta_df.drop('split', axis=1)\n","train_meta_df.columns = ['id', 'dim0', 'dim1']\n","\n","train_meta_df.head(2)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T18:28:08.453841Z","iopub.status.busy":"2021-06-01T18:28:08.453417Z","iopub.status.idle":"2021-06-01T18:28:08.493345Z","shell.execute_reply":"2021-06-01T18:28:08.492352Z","shell.execute_reply.started":"2021-06-01T18:28:08.453802Z"},"trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>boxes</th>\n      <th>label</th>\n      <th>StudyInstanceUID</th>\n      <th>path</th>\n      <th>image_level</th>\n      <th>dim0</th>\n      <th>dim1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000a312787f2</td>\n      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n      <td>5776db0cec75</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>opacity</td>\n      <td>3488</td>\n      <td>4256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c3a3f293f</td>\n      <td>NaN</td>\n      <td>none 1 0 0 1 1</td>\n      <td>ff0879eb20ed</td>\n      <td>/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...</td>\n      <td>none</td>\n      <td>2320</td>\n      <td>2832</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             id                                              boxes  \\\n0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n1  000c3a3f293f                                                NaN   \n\n                                               label StudyInstanceUID  \\\n0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n1                                     none 1 0 0 1 1     ff0879eb20ed   \n\n                                                path image_level  dim0  dim1  \n0  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...     opacity  3488  4256  \n1  /host_Data/DataSets/Kaggle-SIIM Covid 19/siim-...        none  2320  2832  "},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Merge both the dataframes\n","df = df.merge(train_meta_df, on='id',how=\"left\")\n","df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["## üçò Train-validation split"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-06-01T18:28:17.844733Z","iopub.status.busy":"2021-06-01T18:28:17.8444Z","iopub.status.idle":"2021-06-01T18:28:17.876654Z","shell.execute_reply":"2021-06-01T18:28:17.875815Z","shell.execute_reply.started":"2021-06-01T18:28:17.844698Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[key] = value\n","/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_column(loc, value, pi)\n"]}],"source":["# Create train and validation split.\n","train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.image_level.values)\n","\n","train_df.loc[:, 'split'] = 'train'\n","valid_df.loc[:, 'split'] = 'valid'\n","\n","df = pd.concat([train_df, valid_df]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:06:52.778823Z","iopub.status.busy":"2021-06-01T19:06:52.778499Z","iopub.status.idle":"2021-06-01T19:06:52.786144Z","shell.execute_reply":"2021-06-01T19:06:52.785076Z","shell.execute_reply.started":"2021-06-01T19:06:52.778794Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of dataset: 6334, training images: 5067. validation images: 1267\n"]}],"source":["print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"]},{"cell_type":"markdown","metadata":{},"source":["## üçö Prepare Required Folder Structure\n","\n","The required folder structure for the dataset directory is: \n","\n","```\n","/parent_folder\n","    /dataset\n","         /images\n","             /train\n","             /val\n","         /labels\n","             /train\n","             /val\n","    /yolov5\n","```\n","\n","Note that I have named the directory `covid`."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:06:54.934923Z","iopub.status.busy":"2021-06-01T19:06:54.934605Z","iopub.status.idle":"2021-06-01T19:06:55.572448Z","shell.execute_reply":"2021-06-01T19:06:55.571473Z","shell.execute_reply.started":"2021-06-01T19:06:54.934892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ls: cannot access 'tmp/covid/images': No such file or directory\n"]}],"source":["os.makedirs(path_dicom / 'DS-xhlulu_256/tmp/covid/images/train', exist_ok=True)\n","os.makedirs(path_dicom / 'DS-xhlulu_256/tmp/covid/images/valid', exist_ok=True)\n","\n","os.makedirs(path_dicom / 'DS-xhlulu_256/tmp/covid/labels/train', exist_ok=True)\n","os.makedirs(path_dicom / 'DS-xhlulu_256/tmp/covid/labels/valid', exist_ok=True)\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid19-detection/train/badf2d31cdbd.jpg\n"]}],"source":["str(path_dicom / f'DS-xhlulu_256/tmp/covid/images/valid/{row.id}.jpg')\n","print(row.path)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:06:56.706854Z","iopub.status.busy":"2021-06-01T19:06:56.706534Z","iopub.status.idle":"2021-06-01T19:07:03.610811Z","shell.execute_reply":"2021-06-01T19:07:03.609958Z","shell.execute_reply.started":"2021-06-01T19:06:56.706822Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6334 [00:00<?, ?it/s]\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid19-detection/train/badf2d31cdbd.jpg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-c27f20dc08b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'xhlulu_256/tmp/covid/images/train/{row.id}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'xhlulu_256/tmp/covid/images/valid/{row.id}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid19-detection/train/badf2d31cdbd.jpg'"]}],"source":["# Move the images to relevant split folder.\n","for i in tqdm(range(len(df))):\n","    row = df.loc[i]\n","    if row.split == 'train':\n","        copyfile(row.path, f'xhlulu_256/tmp/covid/images/train/{row.id}.jpg')\n","    else:\n","        copyfile(row.path, f'xhlulu_256/tmp/covid/images/valid/{row.id}.jpg')"]},{"cell_type":"markdown","metadata":{},"source":["## üçú Create `.YAML` file\n","\n","The `data.yaml`, is the dataset configuration file that defines \n","\n","1. an \"optional\" download command/URL for auto-downloading, \n","2. a path to a directory of training images (or path to a *.txt file with a list of training images), \n","3. a path to a directory of validation images (or path to a *.txt file with a list of validation images), \n","4. the number of classes, \n","5. a list of class names.\n","\n","> üìç Important: In this competition, each image can either belong to `opacity` or `none` image-level labels. That's why I have  used the number of classes, `nc` to be 2. YOLOv5 automatically handles the images without any bounding box coordinates. \n","\n","> üìç Note: The `data.yaml` is created in the `yolov5/data` directory as required. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:07:05.681955Z","iopub.status.busy":"2021-06-01T19:07:05.681646Z","iopub.status.idle":"2021-06-01T19:07:06.316502Z","shell.execute_reply":"2021-06-01T19:07:06.31555Z","shell.execute_reply.started":"2021-06-01T19:07:05.681924Z"},"trusted":true},"outputs":[],"source":["# Create .yaml file \n","import yaml\n","\n","data_yaml = dict(\n","    train = '../covid/images/train',\n","    val = '../covid/images/valid',\n","    nc = 2,\n","    names = ['none', 'opacity']\n",")\n","\n","# Note that I am creating the file in the yolov5/data/ directory.\n","with open('tmp/yolov5/data/data.yaml', 'w') as outfile:\n","    yaml.dump(data_yaml, outfile, default_flow_style=True)\n","    \n","%cat tmp/yolov5/data/data.yaml"]},{"cell_type":"markdown","metadata":{},"source":["## üçÆ Prepare Bounding Box Coordinated for YOLOv5\n","\n","For every image with **bounding box(es)** a `.txt` file with the same name as the image will be created in the format shown below:\n","\n","* One row per object. <br>\n","* Each row is class `x_center y_center width height format`. <br>\n","* Box coordinates must be in normalized xywh format (from 0 - 1). We can normalize by the boxes in pixels by dividing `x_center` and `width` by image width, and `y_center` and `height` by image height. <br>\n","* Class numbers are zero-indexed (start from 0). <br>\n","\n","> üìç Note: We don't have to remove the images without bounding boxes from the training or validation sets. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:07:16.644777Z","iopub.status.busy":"2021-06-01T19:07:16.644441Z","iopub.status.idle":"2021-06-01T19:07:16.65554Z","shell.execute_reply":"2021-06-01T19:07:16.654512Z","shell.execute_reply.started":"2021-06-01T19:07:16.644736Z"},"trusted":true},"outputs":[],"source":["# Get the raw bounding box by parsing the row value of the label column.\n","# Ref: https://www.kaggle.com/yujiariyasu/plot-3positive-classes\n","def get_bbox(row):\n","    bboxes = []\n","    bbox = []\n","    for i, l in enumerate(row.label.split(' ')):\n","        if (i % 6 == 0) | (i % 6 == 1):\n","            continue\n","        bbox.append(float(l))\n","        if i % 6 == 5:\n","            bboxes.append(bbox)\n","            bbox = []  \n","            \n","    return bboxes\n","\n","# Scale the bounding boxes according to the size of the resized image. \n","def scale_bbox(row, bboxes):\n","    # Get scaling factor\n","    scale_x = IMG_SIZE/row.dim1\n","    scale_y = IMG_SIZE/row.dim0\n","    \n","    scaled_bboxes = []\n","    for bbox in bboxes:\n","        x = int(np.round(bbox[0]*scale_x, 4))\n","        y = int(np.round(bbox[1]*scale_y, 4))\n","        x1 = int(np.round(bbox[2]*(scale_x), 4))\n","        y1= int(np.round(bbox[3]*scale_y, 4))\n","\n","        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n","        \n","    return scaled_bboxes\n","\n","# Convert the bounding boxes in YOLO format.\n","def get_yolo_format_bbox(img_w, img_h, bboxes):\n","    yolo_boxes = []\n","    for bbox in bboxes:\n","        w = bbox[2] - bbox[0] # xmax - xmin\n","        h = bbox[3] - bbox[1] # ymax - ymin\n","        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n","        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n","        \n","        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n","    \n","    return yolo_boxes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:07:20.269881Z","iopub.status.busy":"2021-06-01T19:07:20.269559Z","iopub.status.idle":"2021-06-01T19:07:22.991932Z","shell.execute_reply":"2021-06-01T19:07:22.991054Z","shell.execute_reply.started":"2021-06-01T19:07:20.269852Z"},"trusted":true},"outputs":[],"source":["# Prepare the txt files for bounding box\n","for i in tqdm(range(len(df))):\n","    row = df.loc[i]\n","    # Get image id\n","    img_id = row.id\n","    # Get split\n","    split = row.split\n","    # Get image-level label\n","    label = row.image_level\n","    \n","    if row.split=='train':\n","        file_name = f'tmp/covid/labels/train/{row.id}.txt'\n","    else:\n","        file_name = f'tmp/covid/labels/valid/{row.id}.txt'\n","        \n","    \n","    if label=='opacity':\n","        # Get bboxes\n","        bboxes = get_bbox(row)\n","        # Scale bounding boxes\n","        scale_bboxes = scale_bbox(row, bboxes)\n","        # Format for YOLOv5\n","        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n","        \n","        with open(file_name, 'w') as f:\n","            for bbox in yolo_bboxes:\n","                bbox = [1]+bbox\n","                bbox = [str(i) for i in bbox]\n","                bbox = ' '.join(bbox)\n","                f.write(bbox)\n","                f.write('\\n')"]},{"cell_type":"markdown","metadata":{},"source":["# üöÖ Train with W&B\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:07:28.014031Z","iopub.status.busy":"2021-06-01T19:07:28.013722Z","iopub.status.idle":"2021-06-01T19:07:28.022921Z","shell.execute_reply":"2021-06-01T19:07:28.021983Z","shell.execute_reply.started":"2021-06-01T19:07:28.014002Z"},"trusted":true},"outputs":[],"source":["%cd tmp/yolov5/"]},{"cell_type":"markdown","metadata":{},"source":["```\n","--img {IMG_SIZE} \\ # Input image size.\n","--batch {BATCH_SIZE} \\ # Batch size\n","--epochs {EPOCHS} \\ # Number of epochs\n","--data data.yaml \\ # Configuration file\n","--weights yolov5s.pt \\ # Model name\n","--save_period 1\\ # Save model after interval\n","--project kaggle-siim-covid # W&B project name\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-01T19:07:31.062192Z","iopub.status.busy":"2021-06-01T19:07:31.061852Z","iopub.status.idle":"2021-06-01T19:16:23.188499Z","shell.execute_reply":"2021-06-01T19:16:23.187545Z","shell.execute_reply.started":"2021-06-01T19:07:31.06216Z"},"trusted":true},"outputs":[],"source":["!python train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data data.yaml \\\n","                 --weights yolov5s.pt \\\n","                 --save_period 1\\\n","                 --project kaggle-siim-covid"]},{"cell_type":"markdown","metadata":{},"source":["## Model Saved Automatically as Artifact\n","\n","Since it's a kernel based competition, you can easily download the best model from the W&B Artifacts UI and upload as a Kaggle dataset that you can load in your inference kernel (internel disabled).\n","\n","### [Path to saved model $\\rightarrow$](https://wandb.ai/ayush-thakur/kaggle-siim-covid/artifacts/model/run_jbt74n7q_model/4c3ca5752dba99bd227e)\n","\n","![img](https://i.imgur.com/KhRLQvR.png)\n","\n","> üìç Download the model with the `best` alias tagged to it. "]},{"cell_type":"markdown","metadata":{},"source":["# Inference\n","\n","You will probably use a `Submission.ipynb` kernel to run all the predictions. After training a YOLOv5 based object detector -> head to the artifacts page and download the best model -> upload the model as a Kaggle dataset -> Use it with the submission folder. \n","\n","> üìç Note that you might have to clone the YOLOv5 repository in a Kaggle dataset as well. \n","\n","In this section, I will show you how you can do the inference and modify the predicted bounding box coordinates."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-23T19:07:49.662836Z","iopub.status.busy":"2021-05-23T19:07:49.662496Z","iopub.status.idle":"2021-05-23T19:07:49.66761Z","shell.execute_reply":"2021-05-23T19:07:49.666279Z","shell.execute_reply.started":"2021-05-23T19:07:49.662804Z"},"trusted":true},"outputs":[],"source":["TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/' # absolute path"]},{"cell_type":"markdown","metadata":{},"source":["Since I am training the model in this kernel itself, I will not be using the method that I have described above. The best model is saved in the directory `project_name/exp*/weights/best.pt`. In `exp*`, * can be 1, 2, etc. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-23T19:07:51.844324Z","iopub.status.busy":"2021-05-23T19:07:51.843949Z","iopub.status.idle":"2021-05-23T19:07:51.848162Z","shell.execute_reply":"2021-05-23T19:07:51.847242Z","shell.execute_reply.started":"2021-05-23T19:07:51.844293Z"},"trusted":true},"outputs":[],"source":["MODEL_PATH = 'kaggle-siim-covid/exp/weights/best.pt'"]},{"cell_type":"markdown","metadata":{},"source":["```\n","--weights {MODEL_PATH} \\ # path to the best model.\n","--source {TEST_PATH} \\ # absolute path to the test images.\n","--img {IMG_SIZE} \\ # Size of image\n","--conf 0.281 \\ # Confidence threshold (default is 0.25)\n","--iou-thres 0.5 \\ # IOU threshold (default is 0.45)\n","--max-det 3 \\ # Number of detections per image (default is 1000) \n","--save-txt \\ # Save predicted bounding box coordinates as txt files\n","--save-conf # Save the confidence of prediction for each bounding box\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-06-01T19:17:14.718128Z","iopub.status.busy":"2021-06-01T19:17:14.717733Z","iopub.status.idle":"2021-06-01T19:17:17.912978Z","shell.execute_reply":"2021-06-01T19:17:17.911965Z","shell.execute_reply.started":"2021-06-01T19:17:14.718085Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["!python detect.py --weights {MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img {IMG_SIZE} \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"]},{"cell_type":"markdown","metadata":{},"source":["### How to find the confidence score?\n","\n","1. First first the [W&B run page](https://wandb.ai/ayush-thakur/kaggle-siim-covid/runs/jbt74n7q) generated by training the YOLOv5 model. \n","\n","2. Go to the media panel -> click on the F1_curve.png file to get a rough estimate of the threshold -> go to the Bounding Box Debugger panel and interactively adjust the confidence threshold. \n","\n","![img](https://i.imgur.com/cCUnTBw.gif)"]},{"cell_type":"markdown","metadata":{},"source":["> üìç The bounding box coordinates are saved as text file per image name. It is saved in this directory `runs/detect/exp3/labels`. "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-06-01T19:17:31.798397Z","iopub.status.busy":"2021-06-01T19:17:31.798023Z","iopub.status.idle":"2021-06-01T19:17:32.51175Z","shell.execute_reply":"2021-06-01T19:17:32.510698Z","shell.execute_reply.started":"2021-06-01T19:17:31.798364Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["PRED_PATH = 'runs/detect/exp3/labels'\n","!ls {PRED_PATH}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-23T23:49:14.79253Z","iopub.status.busy":"2021-05-23T23:49:14.792212Z","iopub.status.idle":"2021-05-23T23:49:15.427611Z","shell.execute_reply":"2021-05-23T23:49:15.426681Z","shell.execute_reply.started":"2021-05-23T23:49:14.792498Z"},"trusted":true},"outputs":[],"source":["# Visualize predicted coordinates.\n","%cat runs/detect/exp3/labels/ba91d37ee459.txt"]},{"cell_type":"markdown","metadata":{},"source":["> üìç Note: 1 is class id (opacity), the first four float numbers are `x_center`, `y_center`, `width` and `height`. The final float value is `confidence`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-23T23:49:17.65575Z","iopub.status.busy":"2021-05-23T23:49:17.655442Z","iopub.status.idle":"2021-05-23T23:49:17.661362Z","shell.execute_reply":"2021-05-23T23:49:17.660382Z","shell.execute_reply.started":"2021-05-23T23:49:17.655721Z"},"trusted":true},"outputs":[],"source":["prediction_files = os.listdir(PRED_PATH)\n","print('Number of test images predicted as opaque: ', len(prediction_files))"]},{"cell_type":"markdown","metadata":{},"source":["> üìç Out of 1263 test images, 583 were predicted with `opacity` label and thus we have that many prediction txt files."]},{"cell_type":"markdown","metadata":{},"source":["# Submission\n","\n","In this section, I will show how you can use YOLOv5 as object detector and prepare `submission.csv` file."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2021-05-24T00:04:32.640474Z","iopub.status.busy":"2021-05-24T00:04:32.640121Z","iopub.status.idle":"2021-05-24T00:04:32.649309Z","shell.execute_reply":"2021-05-24T00:04:32.64846Z","shell.execute_reply.started":"2021-05-24T00:04:32.640442Z"},"trusted":true},"outputs":[],"source":["# The submisison requires xmin, ymin, xmax, ymax format. \n","# YOLOv5 returns x_center, y_center, width, height\n","def correct_bbox_format(bboxes):\n","    correct_bboxes = []\n","    for b in bboxes:\n","        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n","        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n","\n","        xmin = xc - int(np.round(w/2))\n","        xmax = xc + int(np.round(w/2))\n","        ymin = yc - int(np.round(h/2))\n","        ymax = yc + int(np.round(h/2))\n","        \n","        correct_bboxes.append([xmin, xmax, ymin, ymax])\n","        \n","    return correct_bboxes\n","\n","# Read the txt file generated by YOLOv5 during inference and extract \n","# confidence and bounding box coordinates.\n","def get_conf_bboxes(file_path):\n","    confidence = []\n","    bboxes = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            preds = line.strip('\\n').split(' ')\n","            preds = list(map(float, preds))\n","            confidence.append(preds[-1])\n","            bboxes.append(preds[1:-1])\n","    return confidence, bboxes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T00:04:43.958403Z","iopub.status.busy":"2021-05-24T00:04:43.958093Z","iopub.status.idle":"2021-05-24T00:04:43.97789Z","shell.execute_reply":"2021-05-24T00:04:43.977167Z","shell.execute_reply.started":"2021-05-24T00:04:43.958375Z"},"trusted":true},"outputs":[],"source":["# Read the submisison file\n","sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n","sub_df.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T00:05:07.787407Z","iopub.status.busy":"2021-05-24T00:05:07.787078Z","iopub.status.idle":"2021-05-24T00:05:08.160354Z","shell.execute_reply":"2021-05-24T00:05:08.159234Z","shell.execute_reply.started":"2021-05-24T00:05:07.787378Z"},"trusted":true},"outputs":[],"source":["# Prediction loop for submission\n","predictions = []\n","\n","for i in tqdm(range(len(sub_df))):\n","    row = sub_df.loc[i]\n","    id_name = row.id.split('_')[0]\n","    id_level = row.id.split('_')[-1]\n","    \n","    if id_level == 'study':\n","        # do study-level classification\n","        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n","        \n","    elif id_level == 'image':\n","        # we can do image-level classification here.\n","        # also we can rely on the object detector's classification head.\n","        # for this example submisison we will use YOLO's classification head. \n","        # since we already ran the inference we know which test images belong to opacity.\n","        if f'{id_name}.txt' in prediction_files:\n","            # opacity label\n","            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n","            bboxes = correct_bbox_format(bboxes)\n","            pred_string = ''\n","            for j, conf in enumerate(confidence):\n","                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n","            predictions.append(pred_string[:-1]) \n","        else:\n","            predictions.append(\"None 1 0 0 1 1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-24T00:05:14.382937Z","iopub.status.busy":"2021-05-24T00:05:14.382633Z","iopub.status.idle":"2021-05-24T00:05:14.406141Z","shell.execute_reply":"2021-05-24T00:05:14.405412Z","shell.execute_reply.started":"2021-05-24T00:05:14.382909Z"},"trusted":true},"outputs":[],"source":["sub_df['PredictionString'] = predictions\n","sub_df.to_csv('submission.csv', index=False)\n","sub_df.tail()"]},{"cell_type":"markdown","metadata":{},"source":["# WORK IN PROGRESS\n","\n","Final component is model prediction visualization which is an optional debugging tool I would like to share. :)\n","\n","Consider upvoting if you find the work useful. "]}],"metadata":{"kernelspec":{"display_name":"(venv) siim-covid19","language":"python","name":"siim-covid19"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"orig_nbformat":3},"nbformat":4,"nbformat_minor":4}