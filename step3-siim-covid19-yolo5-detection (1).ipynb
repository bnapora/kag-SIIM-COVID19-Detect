{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nprint(f\"The preinstalled torch version is: {torch.__version__}\")\nversion_cuda = torch.version.cuda\nprint(f\"The preinstalled CUDA version is: {torch.version.cuda}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T17:55:44.732809Z","iopub.execute_input":"2021-08-04T17:55:44.73327Z","iopub.status.idle":"2021-08-04T17:55:46.375337Z","shell.execute_reply.started":"2021-08-04T17:55:44.733178Z","shell.execute_reply":"2021-08-04T17:55:46.373322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install Prerequisites","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:55:46.377117Z","iopub.execute_input":"2021-08-04T17:55:46.377532Z","iopub.status.idle":"2021-08-04T17:57:11.180776Z","shell.execute_reply.started":"2021-08-04T17:55:46.377488Z","shell.execute_reply":"2021-08-04T17:57:11.179514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if version_cuda >= '11.0':\n#     !pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html --upgrade -q\n# else:\n#     !pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html --upgrade -q\n# !pip install torchtext==0.9.0 --upgrade -q\n\n# !pip install fastai==2.3.1 -q\n# !pip install fastcore==1.3.20 -q\n\n# !pip install git+git://github.com/airctic/icevision.git --upgrade -q\n# !pip install git+git://github.com/airctic/icedata.git --upgrade -q\n    \n# if version_cuda >= '11.0':\n#     # Use for CUDA 11.0\n#     !pip install mmcv-full==\"1.3.3\" -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html --upgrade -q   \n# else:\n#     # Use for CUDA 10.x\n#     !pip install mmcv-full==\"1.3.3\" -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html --upgrade -q\n\n# !pip install mmdet==2.12.0 --upgrade -q\n# !pip install yolov5-icevision --upgrade -q","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:57:11.183557Z","iopub.execute_input":"2021-08-04T17:57:11.184049Z","iopub.status.idle":"2021-08-04T17:57:11.192581Z","shell.execute_reply.started":"2021-08-04T17:57:11.183985Z","shell.execute_reply":"2021-08-04T17:57:11.191427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+git://github.com/airctic/icevision.git#egg=icevision[all] --upgrade -q\n!pip install git+git://github.com/airctic/icedata.git -q\n!pip install yolov5-icevision --upgrade -q\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:57:11.196509Z","iopub.execute_input":"2021-08-04T17:57:11.196809Z","iopub.status.idle":"2021-08-04T17:58:49.200073Z","shell.execute_reply.started":"2021-08-04T17:57:11.196781Z","shell.execute_reply":"2021-08-04T17:58:49.198856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import IPython\n# import time\n\n# def restart_ipyhton():\n#     app = IPython.Application.instance()\n#     app.kernel.do_shutdown(True)  \n\n# print('before restart')\n# restart_ipyhton()\n# time.sleep(15)\n# print('after restart')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:58:49.202497Z","iopub.execute_input":"2021-08-04T17:58:49.203077Z","iopub.status.idle":"2021-08-04T17:58:49.212643Z","shell.execute_reply.started":"2021-08-04T17:58:49.202949Z","shell.execute_reply":"2021-08-04T17:58:49.211055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport timm\nfrom timm import *\n\nfrom fastai.vision.all import *\nfrom fastai.vision.learner import _update_first_layer\nfrom fastai.callback.wandb import *","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:58:49.214597Z","iopub.execute_input":"2021-08-04T17:58:49.215359Z","iopub.status.idle":"2021-08-04T17:58:53.656542Z","shell.execute_reply.started":"2021-08-04T17:58:49.215315Z","shell.execute_reply":"2021-08-04T17:58:53.655274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:58:53.658441Z","iopub.execute_input":"2021-08-04T17:58:53.658895Z","iopub.status.idle":"2021-08-04T17:58:53.736961Z","shell.execute_reply.started":"2021-08-04T17:58:53.658831Z","shell.execute_reply":"2021-08-04T17:58:53.735976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from icevision.all import *\nfrom datetime import *\nimport pytz\nfrom icevision.widgets import *","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:58:53.739431Z","iopub.execute_input":"2021-08-04T17:58:53.739813Z","iopub.status.idle":"2021-08-04T17:58:56.548893Z","shell.execute_reply.started":"2021-08-04T17:58:53.739776Z","shell.execute_reply":"2021-08-04T17:58:56.547749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndevice = 'CPU'\nif 'TPU_NAME' in os.environ.keys():\n    if os.environ['XRT_TPU_CONFIG'] is not None: device = 'TPU'\nelif 'CUDA_VERSION' in os.environ.keys():\n    if os.environ['CUDA_VERSION'] is not None: device = 'GPU'\n\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_dcm = Path('/kaggle/input/siim-covid19-detection')\npath_image_resized = '/kaggle/input/siim-covid19-512-images-and-metadata/train'\npath_image_resize_output = '/kaggle/output'\npath_model_save = Path('/kaggle/working/models')\n\n# image_size=512\n# bs=4\n# N_FOLDS = 3\n# set_seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    seed_val = 111\n#     seed_everything(seed_val)\n    fold_num = 0\n    job = 1\n    num_classes = 4\n    image_size = 512\n    model_arch = \"yolo5\"\n    bs = 16\n    num_workers = 0\n#     kfold = 5\n#     loss_func = CrossEntropyLossFlat() # or LabelSmoothingCrossEntropyFlat()\n#     metrics = [error_rate, accuracy, RocAuc(average='macro'), F1Score(average='macro')]\n#     job_name = f'{model_arch}_fold{fold_num}_job{job}'\n#     print(\"Job Name:\", job_name)\n\n#     wandb_project = 'SIIM_classifier_public'\n#     wandb_run_name = job_name\n    \n    if device=='GPU':\n        fp16 = True\n    else:\n        fp16 = False\n    \ncfg = Config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Resized Images for Training Dataset","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 'train'\nsave_dir = f'/kaggle/working/covid19-imgs-{cfg.image_size}px/{split}/'\nos.makedirs(save_dir, exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # use meta data from resized image dataset; need to add resized imageset creation routine using pydicom\n# image_id = []\n# dim0 = []\n# dim1 = []\n# splits = []\n# save_dir_image = save_dir + 'image/'\n# os.makedirs(save_dir_image, exist_ok=True)\n\n# for dirname, _, filenames in tqdm(os.walk(path_dcm / f'{split}')):\n#         for file in filenames:\n#             # set keep_ratio=True to have original aspect ratio\n#             xray = read_xray(os.path.join(dirname, file))\n#             im = resize(xray, size=cfg.image_size)  \n#             im.save(os.path.join(save_dir_image, file.replace('.dcm', '_image.png')))\n#             image_id.append(file.replace('.dcm', ''))\n#             dim0.append(xray.shape[0])\n#             dim1.append(xray.shape[1])\n#             splits.append(split)\n# meta_imgs_resized = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})\n\n# # meta_imgs_resized.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save dataframe to CSV with imgs\n# meta_imgs_resized.to_csv(f'/kaggle/working/covid19-imgs-{cfg.image_size}px/meta_imgs_resized.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"meta_imgs_resized = pd.read_csv('/kaggle/input/covid19imgs512pxmeta/meta_imgs_resized.csv')\nmeta_imgs_resized.head()\n\n# Can skip if image size metadata has image_id column\nmeta_imgs_resized_copy = meta_imgs_resized.copy()\nmeta_imgs_resized_copy.rename(columns={'StudyInstanceUID': 'image_id'}, inplace=True)\nmeta_imgs_resized_copy.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Change column name to 'StudyInstanceUID'\n# meta_imgs_resized_copy = meta_imgs_resized.copy()\n# meta_imgs_resized_copy.rename(columns={'image_id': 'StudyInstanceUID'}, inplace=True)\n# meta_imgs_resized_copy.head(3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save dataframe to CSV with imgs\n# meta_imgs_resized_copy.to_csv(f'/kaggle/working/covid19-imgs-{cfg.image_size}px/meta_imgs_resized.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Create zip of images and meta csv\n# from zipfile import ZipFile\n# import os\n# from os.path import basename\n\n# with ZipFile ('covid19-imgs-512px.zip', 'w') as zipObj:\n#     for folderName, subFolders, filenames, in os.walk(save_dir):\n#         for filename in filenames:\n#             filePath = os.path.join(folderName, filename)\n#             zipObj.write(filePath, basename(filePath))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load DataFrames and Merge Metadata","metadata":{}},{"cell_type":"code","source":"train_image_df = pd.read_csv(path_dcm / 'train_image_level.csv')\n# train_image_df = pd.read_csv(path_dcm / 'train_study_level.csv')\ntrain_df = train_image_df.copy()\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add Kfold split for train/valid\nfold = 0\n\nfrom sklearn.model_selection import GroupKFold\ndf = train_df\n\ngkf  = GroupKFold(n_splits = 5)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups = df.StudyInstanceUID.tolist())):\n    df.loc[val_idx, 'fold'] = fold\n    \ntrain_df = df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create image_id colume from id field\ntrain_df[['image_id', 'image_type']] = train_df['id'].str.split('_', 1, expand=True)\ntrain_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merge image size and original metadata frames\ntrain_df = train_df.merge(meta_imgs_resized_copy, on='image_id')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = f'/kaggle/input/../input/siim-covid19-512-images-and-metadata/train/' + train_df.id + '.png'\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scaled_bbox(row, sz):\n    x_scale = row.dim1/sz\n    y_scale = row.dim0/sz\n#     x_scale = row.width/sz\n#     y_scale = row.height/sz\n    \n    rescaled_bboxes = []\n    if row.bboxes != None:\n        for bbox in row.bboxes:\n            rescaled_bboxes.append( np.array(bbox) / np.array([x_scale, y_scale, x_scale, y_scale]))\n            \n        return rescaled_bboxes\n    else:\n        return None\n    \ndef get_bboxes(val):\n    val = val.split(' ')\n    if val[0] != 'none':\n        bboxes = []\n        for i, e in enumerate(val):\n            if i % 6 == 2:\n                bboxes.append([float(b) for b in val[i : i+4]])\n        return bboxes\n    else:\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['box_label'] = train_df['label'].apply(lambda x: x.split(' ')[0])\ntrain_df['bboxes'] = train_df['label'].apply(lambda x: get_bboxes(x))\ntrain_df['rescaled_bboxes'] = train_df.apply(lambda row: get_scaled_bbox(row, cfg.image_size), axis=1)\ntrain_df['rescaled_bboxes'] = train_df['rescaled_bboxes'].apply(lambda x: [[0, 0,  1, 1]] if x == None else x)\ntrain_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"classes = ['0. opacity']\nlabels = ['opacity']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here ObjectDetectionRecord from icevision and added ClassificationLabelsRecordComponent\ndef ObjectDetectionClassiRecord():\n    return BaseRecord(\n        (\n            FilepathRecordComponent(),\n            InstancesLabelsRecordComponent(),\n            BBoxesRecordComponent(),\n            ClassificationLabelsRecordComponent(),\n#             ScoresRecordComponent(task=Task('tabular')),\n        )\n    )\ntemplate_record = ObjectDetectionClassiRecord()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImgSize = namedtuple(\"ImgSize\", \"width,height\")\n\n#custom parser from icevision - added classification class map and classification labels\nclass CustomParser(Parser):\n    def __init__(self, template_record, img_dir, label_df, idmap):\n        super().__init__(template_record=template_record)\n\n        self.img_dir = img_dir\n        self.df = label_df\n        self.class_map = ClassMap(list(self.df['box_label'].unique()))\n#         self.classi_class_map = ClassMap(['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'], background=None)\n        self.idmap = idmap\n\n    def __iter__(self):\n        for o in self.df.itertuples():\n            yield o\n\n    def __len__(self) -> int:\n        return len(self.df)\n\n    def record_id(self, o):\n        return o.id\n\n    def parse_fields(self, o, record, is_new):\n        if is_new:\n#             record.set_filepath(f'{self.img_dir}/{o.image_id}.png')\n#             record.set_filepath(f'{self.img_dir}/{o.image_id}.jpg')\n            record.set_filepath(o.image_path)\n            record.set_img_size(ImgSize(width=cfg.image_size, height=cfg.image_size))\n            record.detection.set_class_map(self.class_map)\n#             record.classification.set_class_map(self.classi_class_map)\n#             record.classification.set_labels([o.classi_label])\n#             record.tabular.set_scores([o.Modality_n, o.PatientSex_n])\n\n        record.detection.add_bboxes([BBox.from_xyxy(float(bb[0]), float(bb[1]), float(bb[2]), float(bb[3])) for bb in o.rescaled_bboxes])\n        record.detection.add_labels([o.box_label for _ in o.rescaled_bboxes])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idmap = IDMap([o[1].id for o in train_df.iterrows()])\ntrain_idx = [o[1].id for o in train_df[train_df[\"fold\"] != fold].iterrows()]\nvalid_idx = [o[1].id for o in train_df[train_df[\"fold\"] == fold].iterrows()]\nsplit = FixedSplitter([train_idx, valid_idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map = ClassMap(labels)\nclass_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parser = CustomParser(template_record, path_image_resized, train_df, idmap)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_records, valid_records = parser.parse(autofix=True, data_splitter=split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_records(train_records[:6], ncols=3, class_map=class_map)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=cfg.image_size), tfms.A.Normalize()])\nvalid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(cfg.image_size), tfms.A.Normalize()])\n\ntrain_ds = Dataset(train_records, train_tfms)\nvalid_ds = Dataset(valid_records, valid_tfms)\n\n# train_dl = train_dl_m(train_ds, batch_size=bs, num_workers=0, shuffle=True)\n# valid_dl = valid_dl_m(valid_ds, batch_size=bs, num_workers=0, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra_args = {}\nmodel_type = models.ultralytics.yolov5\nbackbone = model_type.backbones.small\n# The yolov5 model requires an img_size parameter\nextra_args['img_size'] = cfg.image_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the mdoel\nmodel = model_type.model(backbone=backbone(pretrained=True), num_classes=len(class_map), **extra_args) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoaders\ntrain_dl = model_type.train_dl(train_ds, batch_size=cfg.bs, num_workers=0, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=cfg.bs, num_workers=0, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_datetime = datetime.now(pytz.timezone('US/Pacific')).strftime(\"%m%d%Y-%H%M\")\n\n\nmodel_save_name = backbone.model_name + '_'  \nmodel_save_name += str(len(parser.class_map)) + 'cls_' \nmodel_save_name += str(cfg.image_size) + 'px_'\nmodel_save_name += str(len(train_ds)) + 'ds_'\nmodel_save_name += run_datetime\nprint(model_save_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn.freeze()\nlearn.lr_find()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.lr1 = 1e-2\ncfg.epochs1 = 2\n\nlearn.fit(cfg.epochs1, cfg.lr1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.callback.tracker import SaveModelCallback, CancelStepException\nmodel_save_path = str(path_model_save / model_save_name)\nsm = SaveModelCallback(fname=model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.lr1 = 1e-2\ncfg.lr2 = 1e-4\ncfg.epochs1 = 1\n\n# Save Model\nlearn.unfreeze()\nlearn.fit_one_cycle(cfg.epochs1, lr_max=slice(cfg.lr2, cfg.lr1), cbs=sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Download model\n# import os\n# os.chdir(r'/kaggle/working/models')\n# from IPython.display import FileLink \n# # FileLink(r'yolov5s_3cls_512px_5068ds_07272021-1530.pth')\n\n# FileLink(r'yolov5s_3cls_512px_5068ds_08022021-1449.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Fastai Model and Load","metadata":{}},{"cell_type":"code","source":"model_tst = model_type.model(backbone=backbone(pretrained=True), num_classes=len(class_map), device=torch.device(\"cuda\"), **extra_args) \nmodel_tst.load_state_dict(torch.load(model_save_path+'.pth'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_type.show_results(model_tst, valid_ds, detection_threshold=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Pytorch Weights and Load Model\n","metadata":{}},{"cell_type":"code","source":"torch.save(model_tst.state_dict(), model_save_path+'.pt')\nmodel_save_path+'.pt'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tst2 = model_type.model(backbone=backbone(pretrained=True), num_classes=len(class_map), device=torch.device(\"cuda\"), **extra_args) \nmodel_tst2.load_state_dict(torch.load(model_save_path+'.pt'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch Prediction\ninfer_dl = model_type.infer_dl(valid_ds, batch_size=1)\npreds = model_type.predict_from_dl(model=model_tst2, infer_dl=infer_dl, detection_threshold=0.25, keep_images=True)\n\n# preds2 = model_type.convert_raw_predictions(model=model_tst2, infer_dl=infer_dl, detection_threshold=0.25, keep_images=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COVID19 Test Dataset Inference \n### Setup Test Images and Metadata","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nif df.shape[0] == 2477:\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsplit = 'test'\nsave_dir = f'/kaggle/tmp/{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'/kaggle/tmp/{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n    im = resize(xray, size=600)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n    im = resize(xray, size=600)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=600)  \n            study = dirname.split('/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'/kaggle/tmp/{split}/image/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=512)  \n            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Images Dataloader","metadata":{}},{"cell_type":"code","source":"save_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nfilenames = []\nfor filename in os.listdir(save_dir):\n    if filename.endswith('.jpg') or filename.endswith('.png'):\n        imgfile = os.path.join(save_dir, filename)\n        images.append(open_img(imgfile))\n        filenames.append(filename)\n    else:\n        continue\n# images = np.array(images)\n# filenames2images = dict(zip(filenames, images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer_tst_ds = Dataset.from_images(images, valid_tfms, class_map)\n# infer_tst_ds = Dataset.from_images(images, valid_tfms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch Prediction\ninfer_tst_dl = model_type.infer_dl(infer_tst_ds, batch_size=1)\npreds = model_type.predict_from_dl(model=model_tst2, infer_dl=infer_tst_dl, detection_threshold=0.012, keep_images=True)\nfilenames2preds = dict(zip(filenames, preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Yolo5 Prediction Output","metadata":{}},{"cell_type":"code","source":"image_ids = []\nPredictionStrings = []\n\nfor filename in filenames2preds.keys():\n    image_id = filename.split('/')[-1].split('.')[0]\n    pred = filenames2preds[filename]\n    pred_labels = getattr(pred.pred.detection,'labels')\n    pred_scores = getattr(pred.pred.detection, 'scores')\n    pred_str = ''\n\n    for i, bbox in enumerate(getattr(pred.pred.detection, 'bboxes')):\n\n        label = str(0)\n        score = str(pred_scores[i])\n        xmin = str(int(float(bbox.xmin)))\n        ymin = str(int(float(bbox.ymin)))\n        xmax = str(int(float(bbox.xmax)))\n        ymax = str(int(float(bbox.ymax)))\n        \n        pred_str += ' ' + str(label)\n        pred_str += ' ' + str(score) \n        pred_str += ' ' + str(xmin) \n        pred_str += ' ' + str(ymin)\n        pred_str += ' ' + str(xmax) \n        pred_str += ' ' + str(ymax)\n        \n    PredictionStrings.append(pred_str) \n    image_ids.append(image_id)\n\npred_df = pd.DataFrame({'id':image_ids,'PredictionString':PredictionStrings})\npred_df.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Yolo5 Detection","metadata":{}},{"cell_type":"code","source":"# for file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n#     print('file_path=', file_path)\n#     image_id = file_path.split('/')[-1].split('.')[0]\n#     print('image_id=', image_id)\n#     w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n#     f = open(file_path, 'r')\n#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n#     # Reorder prediction tensor as label, confidence, bbox (x1,y1,x2,y2)\n#     data = data[:, [0, 5, 1, 2, 3, 4]]\n#     print('data_revised', data)\n#     # Modify prediction tensor to voc format\n#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n#     print('bboxes_beforeloop=', bboxes)\n#     # Modify bbox coordinates from float to int\n#     for idx in range(len(bboxes)):\n#         bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n# #         print('bboxes_loop',idx, '=', bboxes[idx])\n#     image_ids.append(image_id)\n#     PredictionStrings.append(' '.join(bboxes))\n\n\n# pred_df = pd.DataFrame({'id':image_ids,'PredictionString':PredictionStrings})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}