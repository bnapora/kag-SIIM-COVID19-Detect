{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provided by Arshy from Icevision Discord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwknOfVwAEB-",
        "outputId": "aaf83e9f-0396-4598-ce5f-7b0a5a7870bf"
      },
      "outputs": [],
      "source": [
        "# !wget https://raw.githubusercontent.com/airctic/icevision/master/install_colab.sh\n",
        "# !bash install_colab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpPT5Rj3APkx"
      },
      "outputs": [],
      "source": [
        "#!pip install effdet -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "2b59a31cc71343b0b696aff0da64e60a",
            "915165fec2424f2dab6c78c1626d2d37",
            "e5366cf2ef4e4ef6a2f2ac12fad6decb",
            "e2486dfcdb9346ec94b66ceb592691be",
            "cb3e3610e9f1405986d91118e613e001",
            "b39ca1857b7c4fbd86b0205e16eb2a4c",
            "ef124866a87244a58681586dfdbb452d",
            "ee0e512268284beea938f431a0622582",
            "8a3039025d3c45a7be7b1a9f628cecbf",
            "23dd0f4a8e734cf0adf3b71e2bb8b61b",
            "c083b9478d54439e8ce49d6950d9675b"
          ]
        },
        "id": "kchsyhaZPKzw",
        "outputId": "f32447fd-73f4-4c6b-a8ce-b114042f34d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.1 0.8.0 1.8.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import fastai, icevision, torch\n",
        "print(fastai.__version__, icevision.__version__, torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pfb39sBSAWCo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import timm\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "from collections import namedtuple "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2X5lERAoP-0J"
      },
      "outputs": [],
      "source": [
        "from icevision.core import ClassMap\n",
        "from icevision.core.bbox import BBox\n",
        "from icevision.core.tasks import Task\n",
        "from icevision.models.ross.efficientdet.dataloaders import process_train_record, build_infer_batch\n",
        "from icevision.models.ross.efficientdet import convert_raw_predictions\n",
        "from icevision.core.record import BaseRecord\n",
        "from icevision.core.record_components import (FilepathRecordComponent, InstancesLabelsRecordComponent, \n",
        "                                              BBoxesRecordComponent, ClassificationLabelsRecordComponent, \n",
        "                                              ScoresRecordComponent)\n",
        "from icevision.parsers.parser import Parser\n",
        "from icevision.data.dataset import Dataset\n",
        "from icevision import tfms\n",
        "from icevision.models.utils import transform_dl\n",
        "from icevision.metrics.coco_metric import COCOMetricType, COCOMetric\n",
        "from icevision.models.utils import apply_batch_tfms, unload_records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_-XbbovKP_UH"
      },
      "outputs": [],
      "source": [
        "from effdet import get_efficientdet_config, create_model_from_config, unwrap_bench, create_model, load_checkpoint\n",
        "from effdet.bench import _post_process, _batch_detection\n",
        "from effdet.config import set_config_readonly, set_config_writeable\n",
        "from effdet.efficientdet import get_feature_info, BiFpn, BiFpnLayer, HeadNet, _init_weight, _init_weight_alt\n",
        "from effdet.loss import DetectionLoss\n",
        "from effdet.anchors import Anchors, AnchorLabeler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wOJVvAYTQBba"
      },
      "outputs": [],
      "source": [
        "from fastai.tabular.core import TabularPandas, Categorify, FillMissing, Normalize\n",
        "from fastai.tabular.model import get_emb_sz, TabularModel\n",
        "from fastai.data.block import CategoryBlock\n",
        "from fastai.vision.learner import create_head\n",
        "from fastai.callback.hook import num_features_model\n",
        "from fastai.callback.core import Callback\n",
        "from fastai.optimizer import ranger\n",
        "from fastai.losses import CrossEntropyLossFlat\n",
        "from fastai.torch_core import params\n",
        "from fastai.data.load import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ydrMzmT6QUho"
      },
      "outputs": [],
      "source": [
        "from fastcore.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XnkkBpuvQWg7"
      },
      "outputs": [],
      "source": [
        "ImgSize = namedtuple(\"ImgSize\", \"width,height\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp4GlFLwAZel",
        "outputId": "57bbd6b7-51f4-472b-d298-9a1c1a61498b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shBOpEfQXgv"
      },
      "source": [
        "# Paths and preparing df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A33aUjtlQOtM"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = Path('/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid_resize_1024px')\n",
        "path_img = path/'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2Yg4Ws-KQpj_"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid_resize_1024px/COVID_dcm_metadata.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5afff7da1365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdcm_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'COVID_dcm_metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'COVID_train_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'bounding_boxes256.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/.virtualenvs/siim-covid19/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/host_Data/DataSets/Kaggle-SIIM Covid 19/siim-covid_resize_1024px/COVID_dcm_metadata.csv'"
          ]
        }
      ],
      "source": [
        "dcm_df = pd.read_csv(path/'COVID_dcm_metadata.csv')\n",
        "train_df = pd.read_csv(path/'COVID_train_df.csv')\n",
        "bb_df = pd.read_csv(path/'bounding_boxes256.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0TpIXNLQksJ"
      },
      "outputs": [],
      "source": [
        "train_df['image_id'] = train_df['id'].apply(lambda x: f'{x.split(\"_image\")[0]}.jpg')\n",
        "train_df['classi_label'] = train_df[['Negative for Pneumonia', 'Typical Appearance','Indeterminate Appearance', 'Atypical Appearance']].idxmax(1)\n",
        "train_df = train_df[['image_id', 'classi_label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7ihqY3URLV3"
      },
      "outputs": [],
      "source": [
        "dcm_df = dcm_df[['fname', 'Modality', 'PatientSex']]\n",
        "dcm_df['image_id'] = dcm_df.fname.apply(lambda x: f'{x.split(\"/\")[-1].split(\".dcm\")[0]}.jpg')\n",
        "train_df = train_df.merge(dcm_df, on='image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qfgeeaSRMeQ"
      },
      "outputs": [],
      "source": [
        "df = bb_df.merge(train_df, on='image_id')\n",
        "df['box_label'] = df['label'].apply(lambda x: x.split(' ')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cREVKP6sRNiB"
      },
      "outputs": [],
      "source": [
        "df['bboxes'] = None\n",
        "for i, row in df.iterrows():\n",
        "    lab = row['label'].split(' ')\n",
        "    new = []\n",
        "    for j in range(len(lab)):\n",
        "        if (lab[j] == 'opacity') or (lab[j] == 'none'):\n",
        "            new.append(lab[j+2:j+6])\n",
        "    df.loc[i, 'bboxes'] = new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vpzkZMYROqb"
      },
      "outputs": [],
      "source": [
        "df['Modality_n'] = df['Modality'].map({'DX':0, 'CR':1})\n",
        "df['PatientSex_n'] = df['PatientSex'].map({'M':0, 'F':1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obeTclXlRS5m"
      },
      "source": [
        "# Parser and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCdV8kIGRQjd"
      },
      "outputs": [],
      "source": [
        "# Here ObjectDetectionRecord from icevision and added ClassificationLabelsRecordComponent\n",
        "def ObjectDetectionClassiRecord():\n",
        "    return BaseRecord(\n",
        "        (\n",
        "            FilepathRecordComponent(),\n",
        "            InstancesLabelsRecordComponent(),\n",
        "            BBoxesRecordComponent(),\n",
        "            ClassificationLabelsRecordComponent(),\n",
        "            ScoresRecordComponent(task=Task('tabular')),\n",
        "        )\n",
        "    )\n",
        "template_record = ObjectDetectionClassiRecord()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG8zebskRWj0"
      },
      "outputs": [],
      "source": [
        "#custom parser from icevision - added classification class map and classification labels\n",
        "class CustomParser(Parser):\n",
        "    def __init__(self, template_record, img_dir, label_df):\n",
        "        super().__init__(template_record=template_record)\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.df = label_df\n",
        "        self.class_map = ClassMap(list(self.df['box_label'].unique()))\n",
        "        self.classi_class_map = ClassMap(list(self.df['classi_label'].unique()), background=None)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for o in self.df.itertuples():\n",
        "            yield o\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def record_id(self, o):\n",
        "        return o.image_id\n",
        "\n",
        "    def parse_fields(self, o, record, is_new):\n",
        "        if is_new:\n",
        "            record.set_filepath(f'{self.img_dir}/{o.image_id}')\n",
        "            record.set_img_size(ImgSize(width=256, height=256))\n",
        "            record.detection.set_class_map(self.class_map)\n",
        "            record.classification.set_class_map(self.classi_class_map)\n",
        "            record.classification.set_labels([o.classi_label])\n",
        "            record.tabular.set_scores([o.Modality_n, o.PatientSex_n])\n",
        "\n",
        "        record.detection.add_bboxes([BBox.from_xyxy(float(bb[0]), float(bb[1]), float(bb[2]), float(bb[3])) for bb in o.bboxes])\n",
        "        record.detection.add_labels([o.box_label for _ in o.bboxes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "663653062ec44de089c03ee4a28c841f",
            "f4904f0acdc446d7b9785bd22f9d746b",
            "1c69b366842546b185f6d6b9398af068",
            "bea4241fc48f4006a225e1ac7ab36496",
            "97644f3f172045a887f14a040ce168a6",
            "edf6c890924a4c8cbd709f48782dcc00",
            "77d21c41a3cf495e98b5e4bd1a549af8",
            "00cd6c80eab14e4cbdbfab679f6ee186",
            "db09f6bf4a234a859bfa0e75f9ff9786",
            "f0c01cf0dae84a18bc00e9679f6f8d0e",
            "659d9439d1b94aa0ba18acaa0080fb7b",
            "57267e3d79a54f548ed9e0a70946a41a",
            "aab3ac1aae0443fab69e9de8e93fd053",
            "3ee68cfe20274b69a03af426b5567d92",
            "85e4b2ef121743dbafd7ebc25641d2d8",
            "435127ec537e4029bed0ed24f475b3b4",
            "dd8c1424f4924f2cb90379b00d72ee94",
            "4ad7de9e5b6e4b7bb3fdf081c985dcef",
            "e42f40f53d954b71bd3c75a62d403cea",
            "6b4aff9e9bc7462fa3f55b9133251c91",
            "916fcf9881b54c9998e7b962119c683b",
            "4960acb1d5094fbfbad91e4ee052a853",
            "16af14b6b6e14259a436b9b3e6562673",
            "5533bed5306045d5b902444c6e865c62",
            "43d22a39f6c54f23899596602f1e80f5",
            "4c704ef7ae584a8790249a7a27bffb4b",
            "2bb70771e5dd414a9d968229e24191e2",
            "d61fe76716de42258b172dec3352e0bb",
            "8f8a6f896a1f4847b452e029c1e712c6",
            "41ee88d6620b4f36b3f456474ca025f5",
            "283d88ee3fe348e9ab3187c078931203",
            "2d6aabba754f44d484cdb89c6f224628",
            "74dec77194b94839ac242c5e3193b17c"
          ]
        },
        "id": "ZCpUcMsCRXvE",
        "outputId": "d26d917b-fb17-4945-8629-6db2987b5a16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "663653062ec44de089c03ee4a28c841f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6334 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1m\u001b[34m\u001b[1mAutofixing records\u001b[0m\u001b[1m\u001b[34m\u001b[0m\u001b[1m\u001b[0m | \u001b[36micevision.parsers.parser\u001b[0m:\u001b[36mparse\u001b[0m:\u001b[36m136\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57267e3d79a54f548ed9e0a70946a41a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5067 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16af14b6b6e14259a436b9b3e6562673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1267 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "parser = CustomParser(template_record, path_img, df)\n",
        "train_records, valid_records = parser.parse(autofix=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGamxrJBRaWj"
      },
      "outputs": [],
      "source": [
        "#TODO: to add only specific augmentations \n",
        "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=256), tfms.A.Normalize()])\n",
        "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(256), tfms.A.Normalize()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrmD4sdnRbbi"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "train_ds = Dataset(train_records, train_tfms)\n",
        "valid_ds = Dataset(valid_records, valid_tfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EXll1rnRcQo"
      },
      "outputs": [],
      "source": [
        "# the fuction below is extension of build_train_batch. this is to add batch_classi targets[\"classi\"] is for targets for classification\n",
        "def build_train_batch_m(records):\n",
        "\n",
        "    batch_images, batch_bboxes, batch_classes = zip(\n",
        "        *(process_train_record(record) for record in records)\n",
        "    )\n",
        "    batch_classi = [record.classification.label_ids for record in records] #INSERTED CODE\n",
        "    batch_tabular = [record.tabular.scores for record in records] #INSERTED CODE\n",
        "\n",
        "    # convert to tensors\n",
        "    batch_images = torch.stack(batch_images)\n",
        "    batch_bboxes = [tensor(bboxes, dtype=torch.float32) for bboxes in batch_bboxes]\n",
        "    batch_classes = [tensor(classes, dtype=torch.float32) for classes in batch_classes] \n",
        "    batch_classi = [tensor(classes, dtype=torch.float32) for classes in batch_classi] #INSERTED CODE\n",
        "    batch_tabular = [tensor(scores, dtype=torch.int32) for scores in batch_tabular] #INSERTED CODE\n",
        "\n",
        "    # convert to EffDet interface\n",
        "    targets = dict(bbox=batch_bboxes, cls=batch_classes, tab=batch_tabular, classi=batch_classi)\n",
        "\n",
        "    return (batch_images, targets), records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2b1aTMaRdfw"
      },
      "outputs": [],
      "source": [
        "# the fuction below make use of build_train_batch_ to build valid_ds\n",
        "def build_valid_batch_m(records):\n",
        "\n",
        "    (batch_images, targets), records = build_train_batch_m(records)\n",
        "\n",
        "    # convert to EffDet interface, when not training, dummy size and scale is required\n",
        "    targets = dict(img_size=None, img_scale=None, **targets)\n",
        "\n",
        "    return (batch_images, targets), records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dE82FGKRekH"
      },
      "outputs": [],
      "source": [
        "def transform_dl_m(dataset, build_batch, batch_tfms=None, **dataloader_kwargs):\n",
        "    \"\"\"Creates collate_fn from build_batch by decorating it with apply_batch_tfms and unload_records\"\"\"\n",
        "    collate_fn = apply_batch_tfms(build_batch, batch_tfms=batch_tfms)\n",
        "    collate_fn = unload_records(collate_fn)\n",
        "    return DataLoader(dataset=dataset, create_batch=collate_fn, **dataloader_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49OQe1zbRfmD"
      },
      "outputs": [],
      "source": [
        "def train_dl_m(dataset, batch_tfms=None, **dataloader_kwargs):\n",
        "    return transform_dl_m(\n",
        "        dataset=dataset,\n",
        "        build_batch=build_train_batch_m,\n",
        "        batch_tfms=batch_tfms,\n",
        "        **dataloader_kwargs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8YBARYVRhKS"
      },
      "outputs": [],
      "source": [
        "def valid_dl_m(dataset, batch_tfms=None, **dataloader_kwargs):\n",
        "    return transform_dl_m(\n",
        "                        dataset=dataset,\n",
        "                        build_batch=build_valid_batch_m,\n",
        "                        batch_tfms=batch_tfms,\n",
        "                        **dataloader_kwargs\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTf6LA2lRiTy"
      },
      "outputs": [],
      "source": [
        "train_dl = train_dl_m(train_ds, batch_size=8, num_workers=2, shuffle=True)\n",
        "valid_dl = valid_dl_m(valid_ds, batch_size=8, num_workers=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s5TERcURja4"
      },
      "outputs": [],
      "source": [
        "procs = [Categorify, FillMissing, Normalize]\n",
        "cat_names  = ['Modality', 'PatientSex']\n",
        "\n",
        "to = TabularPandas(train_df, procs, cat_names, y_names='classi_label', y_block=CategoryBlock())\n",
        "emb_szs = get_emb_sz(to)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsE82OgdRlIp"
      },
      "source": [
        "# Preparing DetClassiBench + tabular data embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwArH_bqRkqv"
      },
      "outputs": [],
      "source": [
        "#modeified effdet's EfficientDet to calculate classification output from backbone's output\n",
        "class EfficientDetClassi(nn.Module):\n",
        "    def __init__(self, config, pretrained_backbone=True, classi_class=None, emb_szs=emb_szs, alternate_init=False):\n",
        "        super(EfficientDetClassi, self).__init__()\n",
        "        self.config = config\n",
        "        set_config_readonly(self.config)\n",
        "        self.backbone = timm.create_model(\n",
        "            config.backbone_name, features_only=True,\n",
        "            out_indices=self.config.backbone_indices or (2, 3, 4),\n",
        "            pretrained=pretrained_backbone, **config.backbone_args)\n",
        "        feature_info = get_feature_info(self.backbone)\n",
        "        self.fpn = BiFpn(self.config, feature_info)\n",
        "        self.class_net = HeadNet(self.config, num_outputs=self.config.num_classes)\n",
        "        self.box_net = HeadNet(self.config, num_outputs=4)\n",
        "\n",
        "        #INSERTED CODE STARTS\n",
        "        backbone_features = num_features_model(nn.Sequential(*self.backbone.children()))\n",
        "        self.vis_head = create_head(backbone_features, 100) #fastai's create_head\n",
        "        self.tab = TabularModel(emb_szs, n_cont=0, out_sz = 100, layers = [100, 250])\n",
        "        self.final_head = nn.Sequential(\n",
        "                                        nn.BatchNorm1d(200),\n",
        "                                        nn.Dropout(0.25),\n",
        "                                        nn.Linear(200, 100, bias=False),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.BatchNorm1d(100),\n",
        "                                        nn.Dropout(0.5),\n",
        "                                        nn.Linear(100, 4)\n",
        "                                            )  \n",
        "        #INSERTED CODE ENDS\n",
        "        \n",
        "        '''\n",
        "        self.classifier = nn.Sequential(\n",
        "                                        nn.AdaptiveMaxPool2d(output_size=1),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.BatchNorm1d(backbone_features),\n",
        "                                        nn.Dropout(p=0.25, inplace=False),\n",
        "                                        nn.Linear(backbone_features, 512),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.BatchNorm1d(512),\n",
        "                                        nn.Dropout(p=0.25, inplace=False),\n",
        "                                        nn.Linear(512, classi_class), \n",
        "        )\n",
        "  \n",
        "        '''\n",
        "        for n, m in self.named_modules():\n",
        "            if 'backbone' not in n:\n",
        "                if alternate_init:\n",
        "                    _init_weight_alt(m, n)\n",
        "                else:\n",
        "                    _init_weight(m, n)\n",
        "\n",
        "    @torch.jit.ignore()\n",
        "    def reset_head(self, num_classes=None, aspect_ratios=None, num_scales=None, alternate_init=False):\n",
        "        reset_class_head = False\n",
        "        reset_box_head = False\n",
        "        set_config_writeable(self.config)\n",
        "        if num_classes is not None:\n",
        "            reset_class_head = True\n",
        "            self.config.num_classes = num_classes\n",
        "        if aspect_ratios is not None:\n",
        "            reset_box_head = True\n",
        "            self.config.aspect_ratios = aspect_ratios\n",
        "        if num_scales is not None:\n",
        "            reset_box_head = True\n",
        "            self.config.num_scales = num_scales\n",
        "        set_config_readonly(self.config)\n",
        "\n",
        "        if reset_class_head:\n",
        "            self.class_net = HeadNet(self.config, num_outputs=self.config.num_classes)\n",
        "            for n, m in self.class_net.named_modules(prefix='class_net'):\n",
        "                if alternate_init:\n",
        "                    _init_weight_alt(m, n)\n",
        "                else:\n",
        "                    _init_weight(m, n)\n",
        "\n",
        "        if reset_box_head:\n",
        "            self.box_net = HeadNet(self.config, num_outputs=4)\n",
        "            for n, m in self.box_net.named_modules(prefix='box_net'):\n",
        "                if alternate_init:\n",
        "                    _init_weight_alt(m, n)\n",
        "                else:\n",
        "                    _init_weight(m, n)\n",
        "\n",
        "    @torch.jit.ignore()\n",
        "    def toggle_head_bn_level_first(self):\n",
        "        \"\"\" Toggle the head batchnorm layers between being access with feature_level first vs repeat\n",
        "        \"\"\"\n",
        "        self.class_net.toggle_bn_level_first()\n",
        "        self.box_net.toggle_bn_level_first()\n",
        "\n",
        "    def forward(self, x, tab):\n",
        "        x_b = self.backbone(x)\n",
        "        x = self.fpn(x_b)\n",
        "        x_class = self.class_net(x)\n",
        "        x_box = self.box_net(x)\n",
        "        x_classi_vis = self.vis_head(x_b[2])   #INSERTED CODE\n",
        "        x_class_tab = self.tab(tab)            #INSERTED CODE\n",
        "        x_classi = self.final_head(torch.cat([x_class_tab, x_classi_vis], dim=1))\n",
        "        return x_class, x_box, x_classi #returns x_classi on top of original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p3So5S7RoK8"
      },
      "outputs": [],
      "source": [
        "# Used DetBenchTrain  \n",
        "class DetClassiBenchTrain(nn.Module):\n",
        "    def __init__(self, model, create_labeler=True):\n",
        "        super(DetClassiBenchTrain, self).__init__()\n",
        "        self.model = model\n",
        "        self.config = model.config\n",
        "        self.num_levels = model.config.num_levels\n",
        "        self.num_classes = model.config.num_classes\n",
        "        self.anchors = Anchors.from_config(model.config)\n",
        "        self.max_detection_points = model.config.max_detection_points\n",
        "        self.max_det_per_image = model.config.max_det_per_image\n",
        "        self.soft_nms = model.config.soft_nms\n",
        "        self.anchor_labeler = None\n",
        "        if create_labeler:\n",
        "            self.anchor_labeler = AnchorLabeler(self.anchors, self.num_classes, match_threshold=0.5)\n",
        "        self.loss_fn = DetectionLoss(model.config)\n",
        "        self.classi_loss = CrossEntropyLossFlat() #INSERTED CODE - loss_fn for classification loss\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        tab = torch.stack(target['tab']).type(torch.LongTensor).to('cuda')\n",
        "        class_out, box_out, classi_out = self.model(x, tab) #OUTPUTS INCLUDE classiicaiton predictions\n",
        "        if self.anchor_labeler is None:\n",
        "            # target should contain pre-computed anchor labels if labeler not present in bench\n",
        "            assert 'label_num_positives' in target\n",
        "            cls_targets = [target[f'label_cls_{l}'] for l in range(self.num_levels)]\n",
        "            box_targets = [target[f'label_bbox_{l}'] for l in range(self.num_levels)]\n",
        "            num_positives = target['label_num_positives']\n",
        "        else:\n",
        "            cls_targets, box_targets, num_positives = self.anchor_labeler.batch_label_anchors(\n",
        "                target['bbox'], target['cls'])\n",
        "\n",
        "        classi_targets = torch.stack(target['classi']).squeeze().type(torch.LongTensor).to('cuda')\n",
        "        loss, class_loss, box_loss = self.loss_fn(class_out, box_out, cls_targets, box_targets, num_positives)\n",
        "        \n",
        "        #INSERTED CODE STARTS\n",
        "        classi_loss = self.classi_loss(classi_out, classi_targets)\n",
        "        loss += classi_loss\n",
        "        #INSERTED CODE ENDS\n",
        "\n",
        "        output = {'loss': loss, 'class_loss': class_loss, 'box_loss': box_loss, 'classi_pred':classi_out, 'classi_loss':classi_loss} #ADDED \"classi_loss\"\n",
        "\n",
        "        if not self.training:\n",
        "            # if eval mode, output detections for evaluation\n",
        "            class_out_pp, box_out_pp, indices, classes = _post_process(\n",
        "                class_out, box_out, num_levels=self.num_levels, num_classes=self.num_classes,\n",
        "                max_detection_points=self.max_detection_points)\n",
        "            output['detections'] = _batch_detection(\n",
        "                x.shape[0], class_out_pp, box_out_pp, self.anchors.boxes, indices, classes,\n",
        "                target['img_scale'], target['img_size'],\n",
        "                max_det_per_image=self.max_det_per_image, soft_nms=self.soft_nms)\n",
        "            \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc8KPteORp5G"
      },
      "outputs": [],
      "source": [
        "def create_model_m(model_name, bench_task='', num_classes=None, pretrained=False,\n",
        "                 checkpoint_path='', checkpoint_ema=False, img_size=None, **kwargs):\n",
        "\n",
        "    config = get_efficientdet_config(model_name)\n",
        "    config.image_size = (img_size, img_size) if isinstance(img_size, int) else img_size\n",
        "\n",
        "    return create_model_from_config_m(config, bench_task=bench_task, num_classes=num_classes, pretrained=pretrained,\n",
        "                                      checkpoint_path=checkpoint_path, checkpoint_ema=checkpoint_ema, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4beHkiHIRrNm"
      },
      "outputs": [],
      "source": [
        "def create_model_from_config_m(\n",
        "        config, bench_task='', num_classes=None, pretrained=False,\n",
        "        checkpoint_path='', checkpoint_ema=False, **kwargs):\n",
        "\n",
        "    pretrained_backbone = kwargs.pop('pretrained_backbone', True)\n",
        "    if pretrained or checkpoint_path:\n",
        "        pretrained_backbone = False  # no point in loading backbone weights\n",
        "\n",
        "    # Config overrides, override some config values via kwargs.\n",
        "    overrides = (\n",
        "        'redundant_bias', 'label_smoothing', 'legacy_focal', 'jit_loss', 'soft_nms', 'max_det_per_image', 'image_size')\n",
        "    for ov in overrides:\n",
        "        value = kwargs.pop(ov, None)\n",
        "        if value is not None:\n",
        "            setattr(config, ov, value)\n",
        "\n",
        "    labeler = kwargs.pop('bench_labeler', False)\n",
        "\n",
        "    # create the base model\n",
        "    model = EfficientDetClassi(config, pretrained_backbone=pretrained_backbone, **kwargs)\n",
        "    \n",
        "    # pretrained weights are always spec'd for original config, load them before we change the model\n",
        "    if pretrained:\n",
        "        load_pretrained(model, config.url)\n",
        "\n",
        "    # reset model head if num_classes doesn't match configs\n",
        "    if num_classes is not None and num_classes != config.num_classes:\n",
        "        model.reset_head(num_classes=num_classes)\n",
        "\n",
        "    # load an argument specified training checkpoint\n",
        "    if checkpoint_path:\n",
        "        load_checkpoint(model, checkpoint_path, use_ema=checkpoint_ema)\n",
        "\n",
        "    # wrap model in task specific training/prediction bench if set\n",
        "    if bench_task == 'train':\n",
        "        model = DetClassiBenchTrain(model, create_labeler=True)\n",
        "    elif bench_task == 'predict':\n",
        "        model = DetClassiBenchPredict(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juTwFgkPRsZE"
      },
      "outputs": [],
      "source": [
        "def splitter(m):\n",
        "    s = nn.Sequential(*m.model.children())\n",
        "    return L(s[0], s[1:]).map(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlW91EzgRt2m"
      },
      "outputs": [],
      "source": [
        "#lazy hack to report classification accuracy\n",
        "class ClassiAccuracy(Callback):\n",
        "    def after_epoch(self):\n",
        "        self.learn.eval()\n",
        "        acc, count = 0, 0\n",
        "        for xv, yv in self.learn.dls.valid:\n",
        "            out = self.learn.model(xv[0], xv[1])\n",
        "            pred = torch.argmax(out[\"classi_pred\"], 1).detach().to(\"cpu\")\n",
        "            targ = torch.stack(xv[1][\"classi\"]).squeeze().type(torch.LongTensor).detach().to('cpu')\n",
        "            acc += (pred == targ).float().sum()\n",
        "            count += xv[0].shape[0]\n",
        "            \n",
        "        print(f'Epoch {self.learn.epoch} : {acc/count*100:.3}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW8Lw0OiRuyo",
        "outputId": "a09444e5-359b-45fc-fb0e-be36b81419c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b3_aa-84b4657e.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b3_aa-84b4657e.pth\n"
          ]
        }
      ],
      "source": [
        "bench = create_model_m('tf_efficientdet_d3', \n",
        "                        'train',  \n",
        "                        num_classes=len(parser.class_map)-1,\n",
        "                        classi_class=len(parser.classi_class_map),\n",
        "                        img_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jklPFkOvRvoy"
      },
      "outputs": [],
      "source": [
        "model_type = icevision.models.ross.efficientdet\n",
        "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
        "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], \n",
        "                                  model=bench, \n",
        "                                  metrics=metrics,\n",
        "                                  splitter = splitter,\n",
        "                                  opt_func = ranger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dphDvTO1Rygy"
      },
      "outputs": [],
      "source": [
        "learn.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "z1az41XKRzln",
        "outputId": "9a9f2e92-f9bc-4559-f484-e2ab52cfd1dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>COCOMetric</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.201867</td>\n",
              "      <td>2.145974</td>\n",
              "      <td>0.025455</td>\n",
              "      <td>14:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn.fit_flat_cos(1, 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "wrWhzyQ2R1AB",
        "outputId": "e6487254-70d9-494a-cd54-b5ca39a0cb84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>COCOMetric</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.000117</td>\n",
              "      <td>2.000911</td>\n",
              "      <td>0.046562</td>\n",
              "      <td>03:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.884191</td>\n",
              "      <td>1.994362</td>\n",
              "      <td>0.054217</td>\n",
              "      <td>03:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.846415</td>\n",
              "      <td>1.860683</td>\n",
              "      <td>0.066336</td>\n",
              "      <td>03:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 : 60.4\n",
            "Epoch 1 : 60.5\n",
            "Epoch 2 : 62.2\n"
          ]
        }
      ],
      "source": [
        "learn.fit_flat_cos(3, 1e-3, cbs=ClassiAccuracy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "7wEZIKlHTAxL",
        "outputId": "827a16ae-376f-4dcb-b4c9-5ff9f0db21e2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-af165bfaacaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_flat_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mClassiAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
          ]
        }
      ],
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_flat_cos(15, 1e-3, cbs=ClassiAccuracy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBXEGA0VTFoC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "(venv) siim-covid19",
      "language": "python",
      "name": "siim-covid19"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 3
  },
  "nbformat": 4,
  "nbformat_minor": 0
}